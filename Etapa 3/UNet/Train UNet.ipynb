{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3567740-e156-4354-981a-b0812a80fd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/tf/utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7106098-410e-4834-b509-5ea04d0ec4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "# Definir o nível de log do TensorFlow para ERROR\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Attention, Add, BatchNormalization, Lambda, Activation, Multiply, Dense, Flatten, Input, Concatenate, concatenate, UpSampling2D, LayerNormalization, Dropout, Conv2D, Conv2DTranspose, MaxPooling2D, Reshape, Conv2DTranspose\n",
    "from tensorflow import keras\n",
    "from utils import add_white_gaussian_noise, somar_sinais\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "from scipy.signal import stft, istft\n",
    "import librosa\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7187c738-c9ad-4bb9-98a7-f7adf7b14999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sound import Sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d0fc63-45cc-4771-b40b-e535da4b11e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_shape_size = 8192\n",
    "ws = 255\n",
    "ol = 128\n",
    "NORM_FACTOR = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "049cd878-1194-4b91-8da7-983a330c927b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading clean files: 100%|██████████| 5476/5476 [00:02<00:00, 2569.34it/s]\n",
      "Loading noise files: 100%|██████████| 2000/2000 [00:14<00:00, 135.49it/s]\n"
     ]
    }
   ],
   "source": [
    "sound_base = Sound('../../Dados/Base/', '../../Dados/ESC-50-master/audio/', base_shape_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a0b5605-3079-4ee7-adbe-3d8b2e9e737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stft_magnitude_and_phase(signal, sampling_rate=8000, window_size=ws, overlap=ol):\n",
    "    # Calcula a STFT usando a biblioteca librosa\n",
    "    stft_result = librosa.stft(signal, n_fft=window_size, hop_length=overlap)\n",
    "    \n",
    "    magnitude, phase = librosa.magphase(stft_result)\n",
    "    phi = np.angle(phase)\n",
    "    f = librosa.fft_frequencies(sr=sampling_rate, n_fft=window_size)\n",
    "    t = librosa.frames_to_time(np.arange(stft_result.shape[1]), sr=sampling_rate, hop_length=overlap)\n",
    "\n",
    "    return magnitude, phi, f, t\n",
    "\n",
    "def reconstruct_signal_from_stft(magnitude, phi, sampling_rate=8000, window_size=ws, overlap=ol):\n",
    "    # Reconstruct the signal from magnitude and phase\n",
    "    complex_spec = magnitude * np.exp(1j * phi)\n",
    "    signal = librosa.istft(complex_spec, hop_length=overlap)\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7780f925-ddd9-4bc1-8835-aa782aad74e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, sound_files, noise_files):\n",
    "        self.sound_files = sound_files\n",
    "        self.noise_files = noise_files\n",
    "\n",
    "    def generate_sample_completo(self, batch_size=32):\n",
    "        while True:\n",
    "            # Carrega um lote de sons\n",
    "            sound_batch_choices = np.random.choice(self.sound_files.shape[0], size=batch_size, replace=False)\n",
    "            sound_batch = self.sound_files[sound_batch_choices]\n",
    "            \n",
    "            # Carrega um lote de ruídos\n",
    "            noise_batch_choices = np.random.choice(self.noise_files.shape[0], size=batch_size, replace=False)\n",
    "            noise_batch = self.noise_files[noise_batch_choices]\n",
    "            \n",
    "            x_train = []\n",
    "            y_train = []\n",
    "            \n",
    "            # Adiciona ruído a cada som e calcula a nota PESQ\n",
    "            for sound, noise in zip(sound_batch, noise_batch):\n",
    "                # noisy_sound = somar_sinais(sound, noise, sr)\n",
    "                min_valor = np.min(sound)\n",
    "                max_valor = np.max(sound)\n",
    "                \n",
    "                # Defina o novo intervalo desejado\n",
    "                novo_min = -0.4\n",
    "                novo_max = 0.4\n",
    "                \n",
    "                # Realize a escala do sinal para o novo intervalo\n",
    "                sound_escalado = (sound - min_valor) / (max_valor - min_valor) * (novo_max - novo_min) + novo_min\n",
    "\n",
    "                sr = np.random.randint(0, 20, size=(1,)[0])\n",
    "                noisy_sound = somar_sinais(sound_escalado, noise, sr)\n",
    "                \n",
    "                # noisy_sound = add_white_gaussian_noise(noisy_sound, np.random.randint(20, 30, size=(1,)[0]))\n",
    "                noisy_sound = add_white_gaussian_noise(noisy_sound, np.random.randint(20, 30, size=(1,)[0]))\n",
    "                noisy_sound = np.clip(noisy_sound, -1.0, 1.0)\n",
    "                \n",
    "                A, phi, _, _ = calculate_stft_magnitude_and_phase(sound_escalado)\n",
    "                A_noisy, phi_noisy, _, _ = calculate_stft_magnitude_and_phase(noisy_sound)\n",
    "\n",
    "                # A /= NORM_FACTOR\n",
    "                # A_noisy /= NORM_FACTOR\n",
    "\n",
    "                # A = 10*np.log10(A)\n",
    "                # A_noisy = 10*np.log10(A_noisy)\n",
    "\n",
    "                # xA_batch.append(A)\n",
    "                # xphi_batch.append(phi)\n",
    "                # yA_batch.append(A_noisy)\n",
    "                # yphi_batch.append(phi_noisy)\n",
    "                \n",
    "                # Monta o fasor normalizando a faze por Pi\n",
    "                F = np.concatenate([A.reshape(A.shape[0], A.shape[1], 1), (phi.reshape(phi.shape[0], phi.shape[1], 1) / (2*np.pi)) + 0.5], axis=-1)\n",
    "                F_noisy = np.concatenate([A_noisy.reshape(A_noisy.shape[0], A_noisy.shape[1], 1), (phi_noisy.reshape(phi_noisy.shape[0], phi_noisy.shape[1], 1) / (2*np.pi)) + 0.5], axis=-1)\n",
    "                \n",
    "                # Adiciona o exemplo ao lote de treinamento\n",
    "                x_train.append(F_noisy)\n",
    "                y_train.append(F)\n",
    "\n",
    "            x_train = np.array(x_train)\n",
    "            y_train = np.array(y_train)\n",
    "            \n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f23e3d06-5341-44cc-9116-c7ef2d125f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_train = DataGenerator(sound_base.train_X, sound_base.noise_sounds)\n",
    "data_generator_val = DataGenerator(sound_base.val_X, sound_base.noise_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e99a141d-9dba-493b-8881-bb4dea558d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(inputs):\n",
    "    # Codificador\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    # pool2 = BatchNormalization()(pool2)\n",
    "    \n",
    "    # Camada central\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    \n",
    "    # Decodificador\n",
    "    up4 = UpSampling2D(size=(2, 2))(conv3)\n",
    "    up4 = Conv2D(128, 2, activation='relu', padding='same')(up4)\n",
    "    merge4 = concatenate([conv2, up4], axis=3)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(merge4)\n",
    "    \n",
    "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    up5 = Conv2D(64, 2, activation='relu', padding='same')(up5)\n",
    "    merge5 = concatenate([conv1, up5], axis=3)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(merge5)\n",
    "    \n",
    "    # Camada de saída\n",
    "    output = Conv2D(2, 3, activation='linear', padding='same')(conv5)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6358de17-95b2-49cb-abc4-7adcf60c4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet2(inputs):\n",
    "    # Codificador\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    # pool2 = BatchNormalization()(pool2)\n",
    "    \n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    # Camada central\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv6 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    # Decodificador\n",
    "    up1 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    up1 = Conv2D(512, 2, activation='relu', padding='same')(up1)\n",
    "    merge1 = concatenate([conv4, up1], axis=3)\n",
    "    conv7 = Conv2D(512, 3, activation='relu', padding='same')(merge1)\n",
    "\n",
    "    up2 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    up2 = Conv2D(256, 2, activation='relu', padding='same')(up2)\n",
    "    merge2 = concatenate([conv3, up2], axis=3)\n",
    "    conv8 = Conv2D(256, 3, activation='relu', padding='same')(merge2)\n",
    "\n",
    "    up3 = UpSampling2D(size=(2, 2))(conv8)\n",
    "    up3 = Conv2D(128, 2, activation='relu', padding='same')(up3)\n",
    "    merge3 = concatenate([conv2, up3], axis=3)\n",
    "    conv9 = Conv2D(128, 3, activation='relu', padding='same')(merge3)\n",
    "    \n",
    "    up4 = UpSampling2D(size=(2, 2))(conv9)\n",
    "    up4 = Conv2D(64, 2, activation='relu', padding='same')(up4)\n",
    "    merge4 = concatenate([conv1, up4], axis=3)\n",
    "    conv10 = Conv2D(64, 3, activation='relu', padding='same')(merge4)\n",
    "    \n",
    "    # Camada de saída\n",
    "    output = Conv2D(2, 3, activation='relu', padding='same')(conv10)\n",
    "    output = Conv2D(2, 3, activation='relu', padding='same')(output)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b4f8418-5c1f-444a-820d-5e4ec9e2d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_with_attention(inputs):\n",
    "    # Codificador\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)  # Shape esperado: (128, 64, 64)\n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)  # Shape esperado: (64, 32, 64)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)  # Shape esperado: (64, 32, 128)\n",
    "    # attention1 = Attention()([conv2, pool1])  # Adiciona uma camada de atenção\n",
    "    # Shape esperado após a atenção: (64, 32, 128)\n",
    "    # merged1 = concatenate([conv2, attention1], axis=3)  # Shape esperado: (64, 32, 256)\n",
    "\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)  # Shape esperado: (32, 16, 256)\n",
    "    pool2 = BatchNormalization()(pool2)  # Shape não é alterado\n",
    "\n",
    "    # Camada central\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)  # Shape esperado: (32, 16, 256)\n",
    "\n",
    "    # Decodificador\n",
    "    up4 = UpSampling2D(size=(2, 2))(conv3)  # Shape esperado: (64, 32, 256)\n",
    "    up4 = Conv2D(128, 2, activation='relu', padding='same')(up4)  # Shape esperado: (64, 32, 128)\n",
    "    attention2 = Attention()([up4, conv2])  # Adiciona uma camada de atenção\n",
    "    # Shape esperado após a atenção: (64, 32, 128)\n",
    "    merged2 = concatenate([up4, attention2], axis=3)  # Shape esperado: (64, 32, 256)\n",
    "\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(merged2)  # Shape esperado: (64, 32, 128)\n",
    "\n",
    "    up5 = UpSampling2D(size=(2, 2))(conv4)  # Shape esperado: (128, 64, 128)\n",
    "    up5 = Conv2D(64, 2, activation='relu', padding='same')(up5)  # Shape esperado: (128, 64, 64)\n",
    "    attention3 = Attention()([up5, conv1])  # Adiciona uma camada de atenção\n",
    "    # Shape esperado após a atenção: (128, 64, 64)\n",
    "    merged3 = concatenate([up5, attention3], axis=3)  # Shape esperado: (128, 64, 128)\n",
    "\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(merged3)  # Shape esperado: (128, 64, 64)\n",
    "\n",
    "    # Camada de saída\n",
    "    output = Conv2D(2, 3, activation='relu', padding='same')(conv5)  # Shape esperado: (128, 64, 2)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ad7a591-3392-4b41-81bb-1e717576074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina uma função para criar uma U-Net simplificada\n",
    "def create_unet(inputs, type='mag'):\n",
    "    # Codificador\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = BatchNormalization()(pool2)\n",
    "    \n",
    "    # Camada central\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    \n",
    "    # Decodificador\n",
    "    up4 = UpSampling2D(size=(2, 2))(conv3)\n",
    "    up4 = Conv2D(128, 2, activation='relu', padding='same')(up4)\n",
    "    merge4 = concatenate([conv2, up4], axis=3)\n",
    "    conv4 = Conv2D(128, 3, activation='relu', padding='same')(merge4)\n",
    "    \n",
    "    up5 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    up5 = Conv2D(64, 2, activation='relu', padding='same')(up5)\n",
    "    merge5 = concatenate([conv1, up5], axis=3)\n",
    "    conv5 = Conv2D(64, 3, activation='relu', padding='same')(merge5)\n",
    "\n",
    "    if type == 'mag':\n",
    "        # Camada de classificação por pixel\n",
    "        outputs = keras.layers.Conv2D(1, 3, activation=\"relu\", padding=\"same\")(conv5)\n",
    "    if type == 'phase':\n",
    "        # Camada de classificação por pixel\n",
    "        outputs = keras.layers.Conv2D(1, 3, activation=\"sigmoid\", padding=\"same\")(conv5)\n",
    "\n",
    "    return outputs\n",
    "\n",
    "def get_model(inputs):\n",
    "    # Separe os canais de entrada\n",
    "    channel1 = inputs[..., 0:1]\n",
    "    channel2 = inputs[..., 1:2]\n",
    "\n",
    "    # Crie U-Nets separadas para cada canal\n",
    "    output_channel1 = create_unet(channel1)\n",
    "    output_channel2 = create_unet(channel2, type='phase')\n",
    "\n",
    "    # Concatene os resultados de volta em um tensor de forma (128, 64, 2)\n",
    "    outputs = keras.layers.Concatenate()([output_channel1, output_channel2])\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45db6386-a597-4e33-8270-28189be8a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input((128, 64, 2))\n",
    "outputs = unet(inputs)\n",
    "# outputs = unet2(inputs)\n",
    "# outputs = get_model(inputs)\n",
    "# outputs = unet_with_attention(inputs)\n",
    "# outputs = res_unet(inputs)\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a2d4d16-c29a-433d-bf22-def2b5dcbb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128, 64, 2)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 128, 64, 64)  1216        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 64, 32, 64)   0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 64, 32, 128)  73856       ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 32, 16, 128)  0          ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 16, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 64, 32, 256)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 32, 128)  131200      ['up_sampling2d[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 64, 32, 256)  0           ['conv2d_1[0][0]',               \n",
      "                                                                  'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 32, 128)  295040      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 128, 64, 128  0          ['conv2d_4[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 128, 64, 64)  32832       ['up_sampling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 128, 64, 128  0           ['conv2d[0][0]',                 \n",
      "                                )                                 'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 128, 64, 64)  73792       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 128, 64, 2)   1154        ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 904,258\n",
      "Trainable params: 904,258\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "679b7b1f-c220-4ee1-ae0d-4871de0661ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='msle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a66d88e-2037-4c4b-8abe-657f962a7d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch 1\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m validation_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_generator_val\u001b[38;5;241m.\u001b[39mgenerate_sample_completo(batch_size\u001b[38;5;241m=\u001b[39mbatch_size))\n\u001b[1;32m     11\u001b[0m x_val, y_val \u001b[38;5;241m=\u001b[39m validation_batch\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_generator_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_sample_completo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "steps_per_epoch = len(sound_base.train_X) // batch_size\n",
    "\n",
    "print('Starting training')\n",
    "\n",
    "for epoch in range(60):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    # Gera um novo lote de validação para cada época\n",
    "    validation_batch = next(data_generator_val.generate_sample_completo(batch_size=batch_size))\n",
    "    x_val, y_val = validation_batch\n",
    "    \n",
    "    model.fit(data_generator_train.generate_sample_completo(batch_size=batch_size),\n",
    "                     steps_per_epoch=steps_per_epoch,\n",
    "                     epochs=1,\n",
    "                     validation_data=(x_val, y_val),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753f6b1a-3aba-4136-8bda-4522dab36abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current datetime\n",
    "current_datetime = datetime.now()\n",
    "\n",
    "# Format the datetime as a string to use in the file name\n",
    "datetime_str = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "model.save('unet-STFT-20-epochs-'+datetime_str+'.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d04c826-e4c7-4ad1-ac78-9a1920cab4bd",
   "metadata": {},
   "source": [
    "## Teste do modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1bede0-33da-40dd-97e5-7c5de8f6dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = next(data_generator_val.generate_sample_completo(batch_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50ad51e-e219-49c7-b9de-26aa99efb6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(x_test[:, :, : , 0]))\n",
    "print(np.min(x_test[:, :, : , 0]))\n",
    "print(np.max(y_test[:, :, : , 0]))\n",
    "print(np.min(y_test[:, :, : , 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3b3ca9-eca6-4633-873a-7ef978b789ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_f = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9867717c-0f02-4f50-99ca-aea2e8347813",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(F_f))\n",
    "print(np.min(F_f))\n",
    "print(F_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e3e270-8538-4c1b-83fc-981d3307b153",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = y_test.reshape(y_test.shape[1], y_test.shape[2], y_test.shape[3])[:, :, 0]\n",
    "phi = (y_test.reshape(y_test.shape[1], y_test.shape[2], y_test.shape[3])[:, :, 1] - 0.5) * 2 * np.pi\n",
    "\n",
    "A_f = F_f.reshape(F_f.shape[1], F_f.shape[2], F_f.shape[3])[:, :, 0]\n",
    "phi_f = (F_f.reshape(F_f.shape[1], F_f.shape[2], F_f.shape[3])[:, :, 1] - 0.5) * 2 * np.pi\n",
    "\n",
    "A_n = x_test.reshape(x_test.shape[1], x_test.shape[2], x_test.shape[3])[:, :, 0]\n",
    "phi_n = (x_test.reshape(x_test.shape[1], x_test.shape[2], x_test.shape[3])[:, :, 1] - 0.5) * 2 * np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895aa37a-cf39-49f0-81cd-069eecaef3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(A_f))\n",
    "print(np.max(phi_f))\n",
    "print(np.min(A_f))\n",
    "print(np.min(phi_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a79fbd-8e19-453c-9e4a-b5d65be0ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(10, 18))\n",
    "\n",
    "# Primeiro gráfico\n",
    "im = axs[0].imshow(10*np.log10(A), aspect='auto', cmap='inferno')\n",
    "axs[0].set_title('Log Power Spectrum - Som original')\n",
    "axs[0].set_xlabel('Tempo (s)')\n",
    "axs[0].set_ylabel('Frequência (Hz)')\n",
    "fig.colorbar(im, ax=axs[0], format='%+2.0f dB')\n",
    "\n",
    "# Segundo gráfico\n",
    "im = axs[1].imshow(10*np.log10(A_n), aspect='auto', cmap='inferno')\n",
    "axs[1].set_title('Log Power Spectrum - Som ruidoso')\n",
    "axs[1].set_xlabel('Tempo (s)')\n",
    "axs[1].set_ylabel('Frequência (Hz)')\n",
    "fig.colorbar(im, ax=axs[1], format='%+2.0f dB')\n",
    "\n",
    "# Terceiro gráfico\n",
    "im = axs[2].imshow(10*np.log10(A_f), aspect='auto', cmap='inferno')\n",
    "axs[2].set_title('Log Power Spectrum - Sinal filtrado')\n",
    "axs[2].set_xlabel('Tempo (s)')\n",
    "axs[2].set_ylabel('Frequência (Hz)')\n",
    "fig.colorbar(im, ax=axs[2], format='%+2.0f dB')\n",
    "\n",
    "plt.tight_layout()  # Para evitar sobreposição de rótulos e gráficos\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32f16c0-6d02-4d45-a83c-1006104f926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = reconstruct_signal_from_stft(A, phi)\n",
    "s_n = reconstruct_signal_from_stft(A_n, phi_n)\n",
    "s_f = reconstruct_signal_from_stft(A_f, phi_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7a5018-8f1f-4567-ad1d-c1106f8c2dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando figuras e eixos separados para cada array\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1)\n",
    "\n",
    "# Plotando o primeiro array\n",
    "ax1.plot(s)\n",
    "ax1.set_ylabel('Sinal de voz ruidoso')\n",
    "\n",
    "# Plotando o primeiro array\n",
    "ax2.plot(s_n)\n",
    "ax2.set_ylabel('Sinal de voz ruidoso')\n",
    "\n",
    "ax3.plot(s_f)\n",
    "ax3.set_ylabel('Sinal de voz filtrado')\n",
    "\n",
    "# Exibindo os gráficos\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a389d0-497c-4ae8-9aff-56776fa842f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=s, rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb57a8c-701e-4752-b5e9-3b454dc1c09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=s_n, rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f672d7fd-a5e8-480d-a439-c124537bed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=s_f, rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d362a5e-46e0-48ae-b769-206d7a587071",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
