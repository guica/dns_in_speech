{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a0ad97-f8ed-4fc5-acfd-188d592a7e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/tf/utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a8c9e74-5718-46f6-9c6d-d000cf70b8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_shape_size = 8192\n",
    "ws = 255\n",
    "ol = 128\n",
    "input_shape = (128, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee14a338-6a30-4ba3-93e6-60bb0fe8f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import calculate_stft_magnitude_and_phase, reconstruct_signal_from_stft\n",
    "from sound import Sound\n",
    "from data_generators import NoisyTargetGenerator\n",
    "from artigos.testes import create_model\n",
    "import tensorflow as tf\n",
    "# tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Audio\n",
    "from IPython import display\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f1214ce-f3b9-43fb-a7e8-e301715e95ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Speech Files: 100%|██████████| 5725/5725 [00:04<00:00, 1403.45it/s]\n",
      "Loading Noise Files: 100%|██████████| 5695/5695 [00:04<00:00, 1283.17it/s]\n",
      "/tf/utils/sound.py:62: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  clean_sounds = [sound for sound in clean_sounds if sound != self.TOO_SHORT_ERROR]\n",
      "/tf/utils/sound.py:74: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  noise_sounds = [sound for sound in noise_sounds if sound != self.TOO_SHORT_ERROR]\n",
      "Loading Speech Files: 100%|██████████| 1635/1635 [00:02<00:00, 772.87it/s] \n",
      "Loading Noise Files: 100%|██████████| 1627/1627 [00:02<00:00, 739.23it/s] \n"
     ]
    }
   ],
   "source": [
    "sound_base_train = Sound('/tf/Dados/Vozes/train/', '/tf/Dados/Ruido/train/', base_shape_size)\n",
    "sound_base_val = Sound('/tf/Dados/Vozes/val/', '/tf/Dados/Ruido/val/', base_shape_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41feb384-a619-408d-90a6-faaa3b7edd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_train = NoisyTargetGenerator(sound_base_train.clean_sounds, sound_base_train.noise_sounds)\n",
    "data_generator_val = NoisyTargetGenerator(sound_base_val.clean_sounds, sound_base_val.noise_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ebc903b-8bf1-4962-8b46-6a23184d9c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar):\n",
    "    \n",
    "    prediction = model(test_input.reshape(-1, 128, 64, 1), training=True)\n",
    "    plt.figure(figsize=(22, 7))\n",
    "    \n",
    "    display_list = [test_input[0], tar[0], prediction[0]]\n",
    "    title = ['Log Power Spectrum - Som ruidoso', 'Log Power Spectrum - Som original', 'Log Power Spectrum - Som filtrado']\n",
    "    \n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        # Getting the pixel values in the [0, 1] range to plot.\n",
    "        plt.imshow(10 * np.log10((display_list[i][..., 0])**2), aspect='auto', cmap='inferno')\n",
    "        plt.colorbar(format='%+2.0f dB')  # Removi a variável 'im' e 'axs[0]'\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b439de-0205-4660-aff4-94fd5b66a32a",
   "metadata": {},
   "source": [
    "## Estrutura do modelo para 3 canais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fec2cb5-faf4-48aa-9232-5a73d1084a52",
   "metadata": {},
   "source": [
    "![Descrição da imagem](model_structure.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc2aa105-ba63-40b1-9431-345e3575df9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input = (None, 128, 64, 1)\n",
      "Conv block = (None, 128, 64, 64)\n",
      "Channel Attention = (None, 128, 64, 64)\n",
      "Channel Attention Last CNN = (None, 128, 64, 1)\n",
      "First phase = (None, 128, 64, 2)\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"multi_scale_feature_extraction\" (type Multi_scale_feature_extraction).\n\nin user code:\n\n    File \"/tf/utils/artigos/testes.py\", line 225, in call  *\n        up_sample_16 = self.msfe_16(X)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filertr2potj.py\", line 11, in tf__call\n        unet = ag__.converted_call(ag__.ld(self).unet_layers_lstm, (ag__.ld(avg_pool),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'avg_pool__unet__upsample_msfe' (type Avg_pool_Unet_Upsample_msfe).\n    \n    in user code:\n    \n        File \"/tf/utils/artigos/testes.py\", line 207, in call  *\n            unet = self.unet_layers_lstm(avg_pool)\n        File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Input 0 of layer \"AttentionResUNet\" is incompatible with the layer: expected shape=(None, 128, 64, 2), found shape=(None, 16, 16, 2)\n    \n    \n    Call arguments received by layer 'avg_pool__unet__upsample_msfe' (type Avg_pool_Unet_Upsample_msfe):\n      • X=tf.Tensor(shape=(None, 128, 64, 2), dtype=float32)\n\n\nCall arguments received by layer \"multi_scale_feature_extraction\" (type Multi_scale_feature_extraction):\n  • X=tf.Tensor(shape=(None, 128, 64, 2), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# with tf.device('/GPU:0'):\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tf/utils/artigos/testes.py:315\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(input_shape)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst phase =\u001b[39m\u001b[38;5;124m\"\u001b[39m,ca_block\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m--> 315\u001b[0m msfe_block \u001b[38;5;241m=\u001b[39m \u001b[43mMulti_scale_feature_extraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mca_block\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMulti-scale feature extraction =\u001b[39m\u001b[38;5;124m\"\u001b[39m,msfe_block\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    319\u001b[0m ksm \u001b[38;5;241m=\u001b[39m Kernel_selecting_module()(msfe_block)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filezze3tpgn.py:10\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      8\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[0;32m---> 10\u001b[0m up_sample_16 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mmsfe_16, (ag__\u001b[38;5;241m.\u001b[39mld(X),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m up_sample_8 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mmsfe_8, (ag__\u001b[38;5;241m.\u001b[39mld(X),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m up_sample_4 \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mmsfe_4, (ag__\u001b[38;5;241m.\u001b[39mld(X),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filertr2potj.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      9\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m     10\u001b[0m avg_pool \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mavg_pool, (ag__\u001b[38;5;241m.\u001b[39mld(X),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 11\u001b[0m unet \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39munet_layers_lstm, (ag__\u001b[38;5;241m.\u001b[39mld(avg_pool),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     12\u001b[0m upsample \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mupsample, (ag__\u001b[38;5;241m.\u001b[39mld(unet),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"multi_scale_feature_extraction\" (type Multi_scale_feature_extraction).\n\nin user code:\n\n    File \"/tf/utils/artigos/testes.py\", line 225, in call  *\n        up_sample_16 = self.msfe_16(X)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"/tmp/__autograph_generated_filertr2potj.py\", line 11, in tf__call\n        unet = ag__.converted_call(ag__.ld(self).unet_layers_lstm, (ag__.ld(avg_pool),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'avg_pool__unet__upsample_msfe' (type Avg_pool_Unet_Upsample_msfe).\n    \n    in user code:\n    \n        File \"/tf/utils/artigos/testes.py\", line 207, in call  *\n            unet = self.unet_layers_lstm(avg_pool)\n        File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n            raise ValueError(\n    \n        ValueError: Input 0 of layer \"AttentionResUNet\" is incompatible with the layer: expected shape=(None, 128, 64, 2), found shape=(None, 16, 16, 2)\n    \n    \n    Call arguments received by layer 'avg_pool__unet__upsample_msfe' (type Avg_pool_Unet_Upsample_msfe):\n      • X=tf.Tensor(shape=(None, 128, 64, 2), dtype=float32)\n\n\nCall arguments received by layer \"multi_scale_feature_extraction\" (type Multi_scale_feature_extraction):\n  • X=tf.Tensor(shape=(None, 128, 64, 2), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# with tf.device('/GPU:0'):\n",
    "model = create_model(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8c73a2-3c38-48c5-a554-135483a317ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142cbd92-1e4f-4c31-90e1-c35c30418e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df65d6f8-e777-4093-92d8-a90d6f7d8495",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateImagesCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, x_val, y_val):\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        indice_aleatorio = np.random.choice(self.x_val.shape[0])\n",
    "        amostra_noisy_module = self.x_val[indice_aleatorio][np.newaxis, ...]\n",
    "        amostra_original_module = self.y_val[indice_aleatorio][np.newaxis, ...]\n",
    "        generate_images(self.model, amostra_noisy_module, amostra_original_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3478fa-64f7-4d56-a5c7-6abfb08f0c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera um novo lote de validação para cada época\n",
    "validation_batch = next(data_generator_val.generate_sample_completo(batch_size=32))\n",
    "x_val, y_val = validation_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa6e46e-e1df-45b8-9522-68caa47aa640",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch_train = len(sound_base_train.clean_sounds)\n",
    "steps_per_epoch_validation = len(sound_base_val.clean_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498460bc-1050-4060-89d8-0b5456c74f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_path = \"/tf/Etapa 3/Artigos/Testes/model_checkpoints/\"\n",
    "callbacks_lst = [\n",
    "                 tf.keras.callbacks.ModelCheckpoint(filepath=best_models_path+\"best_PRIDNet_blindnoise_128x64.h5\", save_freq=100, save_weights_only=False),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', min_lr=0.0000009, min_delta=0.0001, factor=0.70, patience=3, verbose=1, mode='min'),\n",
    "    # tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, min_delta=0.0001, patience=10),\n",
    "    GenerateImagesCallback(x_val, y_val)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6e05e-d6ed-4a35-9feb-28390d312ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_msle(y_true, y_pred):\n",
    "    # Define o peso para penalizar mais as subestimações\n",
    "    w = 2.0\n",
    "\n",
    "    # Evita valores negativos adicionando 1 antes de aplicar o log\n",
    "    log_true = 20 * tf.math.log(y_true + 1)\n",
    "    log_pred = 20 * tf.math.log(y_pred + 1)\n",
    "\n",
    "    # Cálculo do erro\n",
    "    error = log_true - log_pred\n",
    "\n",
    "    # Aplica pesos diferentes para superestimação e subestimação\n",
    "    weighted_error = tf.where(error > 0, w * error, error)\n",
    "\n",
    "    # Retorna a média do erro logarítmico quadrado ponderado\n",
    "    return tf.reduce_mean(tf.abs(weighted_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85192611-4428-4dd7-8ef5-3a929017b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=Adam(learning_rate=0.0001))\n",
    "# model.compile(loss=tf.keras.losses.MeanAbsoluteError(), optimizer=Adam(learning_rate=0.0009))\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=Adam(\n",
    "        learning_rate=1e-05,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-08,\n",
    "    )\n",
    ")\n",
    "# model.compile(loss=tf.keras.losses.MeanSquaredLogarithmicError(), optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe747e8d-17f4-4639-8eee-f947a944f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "steps_per_epoch = len(sound_base_train.clean_sounds) // batch_size\n",
    "epochs = 200\n",
    "\n",
    "val_data = next(data_generator_val.generate_sample_completo(batch_size=4 * batch_size, include_clean=False, only_return_mudule=True))\n",
    "\n",
    "model.fit(data_generator_train.generate_sample_completo(batch_size=batch_size, include_clean=False, only_return_mudule=True),\n",
    "          steps_per_epoch=steps_per_epoch,\n",
    "          epochs=epochs,\n",
    "          validation_data=val_data,\n",
    "          callbacks=callbacks_lst\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c25d86-c5b8-464d-a568-ced15d2780da",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_batch = next(data_generator_val.generate_sample_completo(batch_size=8))\n",
    "x_test, y_test = validation_batch\n",
    "\n",
    "x_test = x_test[0, ...]\n",
    "y_test = y_test[0, ...]\n",
    "\n",
    "x_test = x_test[np.newaxis, ...]\n",
    "y_test = y_test[np.newaxis, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a4264f-bd8e-4c1e-be83-1a3ef53f8adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(x_test[:, :, : , 0]))\n",
    "print(np.min(x_test[:, :, : , 0]))\n",
    "print(np.max(y_test[:, :, : , 0]))\n",
    "print(np.min(y_test[:, :, : , 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503aa013-7312-4652-a127-70e8d81fbe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a9e9f5-50ab-4e03-a2dc-dd7c1cd76004",
   "metadata": {},
   "outputs": [],
   "source": [
    "F_f = model.predict(x_test[:, :, :, 0].reshape(-1, 128, 64, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72460ef5-ca1a-4085-ac90-4ed0dc15670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(F_f))\n",
    "print(np.min(F_f))\n",
    "print(F_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fe73a5-f35e-4bfd-8834-cccecefe4016",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = y_test.reshape(y_test.shape[1], y_test.shape[2], y_test.shape[3])[:, :, 0]\n",
    "phi = (y_test.reshape(y_test.shape[1], y_test.shape[2], y_test.shape[3])[:, :, 1] - 0.5) * 2 * np.pi\n",
    "\n",
    "A_f = F_f.reshape(F_f.shape[1], F_f.shape[2], F_f.shape[3])[:, :, 0]\n",
    "# phi_f = (F_f.reshape(F_f.shape[1], F_f.shape[2], F_f.shape[3])[:, :, 1] - 0.5) * 2 * np.pi\n",
    "\n",
    "A_n = x_test.reshape(x_test.shape[1], x_test.shape[2], x_test.shape[3])[:, :, 0]\n",
    "phi_n = (x_test.reshape(x_test.shape[1], x_test.shape[2], x_test.shape[3])[:, :, 1] - 0.5) * 2 * np.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad77b55-5bde-4963-a578-497a46955c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(A_f))\n",
    "# print(np.max(phi_f))\n",
    "print(np.min(A_f))\n",
    "# print(np.min(phi_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aa78ff-7929-4a19-aaff-42e41c4dc7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e5503f-d37e-433b-b0da-274e40fce697",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = reconstruct_signal_from_stft(A, phi)\n",
    "s_n = reconstruct_signal_from_stft(A_n, phi_n)\n",
    "s_f = reconstruct_signal_from_stft(A_f, phi_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e3282-c2f6-4375-a957-22ead37810c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando figuras e eixos separados para cada array\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1)\n",
    "\n",
    "# Plotando o primeiro array\n",
    "ax1.plot(s)\n",
    "ax1.set_ylabel('Sinal de voz ruidoso')\n",
    "\n",
    "# Plotando o primeiro array\n",
    "ax2.plot(s_n)\n",
    "ax2.set_ylabel('Sinal de voz ruidoso')\n",
    "\n",
    "ax3.plot(s_f)\n",
    "ax3.set_ylabel('Sinal de voz filtrado')\n",
    "\n",
    "# Exibindo os gráficos\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2425eb2-3e22-47ea-b657-bb2529d12a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=s, rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d397ab-a97a-46a6-a90f-85b4c61d22b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=s_n, rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb70d233-9c96-451b-a4bc-1d1d810e467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=s_f, rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7da47fc-2d85-4259-9b99-4814c0973088",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
