{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bced5b6-43e4-4a74-9272-596e52869639",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/tf/utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0bbde5a-61a6-4ec6-8142-9279bfc3008a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "88024b78-4b51-4c33-9d9a-37a56f5e2fc6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import multiply, Lambda, add, Activation, Dropout, Conv2DTranspose, ReLU, ZeroPadding2D, BatchNormalization, Input, Conv2D, Conv2DTranspose, Flatten, Dense, LeakyReLU, MaxPooling2D, UpSampling2D, Concatenate, concatenate, Bidirectional, LSTM, TimeDistributed, Reshape\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.backend import sigmoid\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from pesq import pesq\n",
    "from utils import calculate_snr, itakura_distortion, somar_sinais, add_white_gaussian_noise, performance\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sound import Sound\n",
    "\n",
    "from IPython.display import Audio\n",
    "import time\n",
    "from IPython import display\n",
    "\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5410d5d1-d0e5-443d-a29c-33185d1600dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d485415d-06f3-4ae8-b081-cd34e9e540a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_shape_size = 8192\n",
    "ws = 255\n",
    "ol = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16da35dd-6c99-48ea-9fa9-4dd9d371046f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Speech Files: 100%|██████████| 8179/8179 [00:07<00:00, 1133.40it/s]\n",
      "Loading Noise Files: 100%|██████████| 8137/8137 [00:08<00:00, 1001.30it/s]\n",
      "/tf/utils/sound.py:65: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  clean_sounds = [sound for sound in clean_sounds if sound != self.TOO_SHORT_ERROR]\n",
      "/tf/utils/sound.py:77: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  noise_sounds = [sound for sound in noise_sounds if sound != self.TOO_SHORT_ERROR]\n"
     ]
    }
   ],
   "source": [
    "sound_base = Sound('../../../Dados/Vozes/', '../../../Dados/Ruido/', base_shape_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce7f33ec-6059-4f99-a952-5be55799a819",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_stft_magnitude_and_phase(signal, sampling_rate=8000, window_size=ws, overlap=ol):\n",
    "    # Calcula a STFT usando a biblioteca librosa\n",
    "    stft_result = librosa.stft(signal, n_fft=window_size, hop_length=overlap)\n",
    "    \n",
    "    magnitude, phase = librosa.magphase(stft_result)\n",
    "    phi = np.angle(phase)\n",
    "    f = librosa.fft_frequencies(sr=sampling_rate, n_fft=window_size)\n",
    "    t = librosa.frames_to_time(np.arange(stft_result.shape[1]), sr=sampling_rate, hop_length=overlap)\n",
    "\n",
    "    return magnitude, phi, f, t\n",
    "\n",
    "def reconstruct_signal_from_stft(magnitude, phi, sampling_rate=8000, window_size=ws, overlap=ol):\n",
    "    # Reconstruct the signal from magnitude and phase\n",
    "    complex_spec = magnitude * np.exp(1j * phi)\n",
    "    signal = librosa.istft(complex_spec, hop_length=overlap)\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ded159e0-2be9-48aa-9494-cdaf522a5f59",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, sound_files, noise_files):\n",
    "        self.sound_files = sound_files\n",
    "        self.noise_files = noise_files\n",
    "\n",
    "    def generate_sample_completo(self, batch_size=32):\n",
    "        while True:\n",
    "            # # Carrega um lote de sons\n",
    "            # sound_batch_choices = np.random.choice(self.sound_files.shape[0], size=batch_size, replace=False)\n",
    "            # sound_batch = self.sound_files[sound_batch_choices]\n",
    "            \n",
    "            # # Carrega um lote de ruídos\n",
    "            # noise_batch_choices = np.random.choice(self.noise_files.shape[0], size=batch_size, replace=False)\n",
    "            # noise_batch = self.noise_files[noise_batch_choices]\n",
    "            block_size = 8\n",
    "            \n",
    "            if batch_size % block_size != 0:\n",
    "                raise ValueError(\"O tamanho do lote deve ser um múltiplo de 8\")\n",
    "\n",
    "            # Calcula quantos blocos de 8 existem nos dados fornecidos\n",
    "            num_blocks = batch_size // block_size\n",
    "            \n",
    "            # Escolhe blocos aleatórios de sons e ruídos\n",
    "            sound_block_indices = np.random.choice(self.sound_files.shape[0] // block_size, size=num_blocks, replace=False) * block_size\n",
    "            noise_block_indices = np.random.choice(self.noise_files.shape[0] // block_size, size=num_blocks, replace=False) * block_size\n",
    "\n",
    "            # Seleciona os arquivos de sons e ruídos\n",
    "            sound_batch = np.array([self.sound_files[i:i+8] for i in sound_block_indices]).reshape(-1, self.sound_files.shape[-1])\n",
    "            noise_batch = np.array([self.noise_files[i:i+8] for i in noise_block_indices]).reshape(-1, self.noise_files.shape[-1])\n",
    "            \n",
    "            # Verifica se reshape não excedeu a quantidade de amostras disponível, ajustando se necessário\n",
    "            if len(sound_batch) > batch_size:\n",
    "                sound_batch = sound_batch[:batch_size]\n",
    "            if len(noise_batch) > batch_size:\n",
    "                noise_batch = noise_batch[:batch_size]\n",
    "\n",
    "            x_train = []\n",
    "            y_train = []\n",
    "            # y_pesq = []\n",
    "            \n",
    "            # Adiciona ruído a cada som e calcula a nota PESQ\n",
    "            for sound, noise in zip(sound_batch, noise_batch):\n",
    "                # noisy_sound = somar_sinais(sound, noise, sr)\n",
    "                try:\n",
    "                    min_valor = np.min(sound)\n",
    "                    max_valor = np.max(sound)\n",
    "                    \n",
    "                    # Defina o novo intervalo desejado\n",
    "                    novo_min = -0.4\n",
    "                    novo_max = 0.4\n",
    "                    \n",
    "                    # Realize a escala do sinal para o novo intervalo\n",
    "                    sound_escalado = (sound - min_valor) / (max_valor - min_valor) * (novo_max - novo_min) + novo_min\n",
    "    \n",
    "                    potencia_sound = np.mean(np.abs(sound_escalado) ** 2.0)\n",
    "                    potencia_noise = np.mean(np.abs(noise) ** 2.0)\n",
    "    \n",
    "                    if potencia_sound > 0. and potencia_noise > 0.:\n",
    "                        sr = np.random.randint(0, 20, size=(1,)[0])\n",
    "                        noisy_sound = somar_sinais(sound_escalado, noise, sr)\n",
    "    \n",
    "                    elif potencia_sound > 0.:\n",
    "                        noisy_sound = sound_escalado\n",
    "    \n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    # noisy_sound = add_white_gaussian_noise(noisy_sound, np.random.randint(20, 30, size=(1,)[0]))\n",
    "                    noisy_sound = add_white_gaussian_noise(noisy_sound, np.random.randint(20, 30, size=(1,)[0]))\n",
    "                    noisy_sound = np.clip(noisy_sound, -1.0, 1.0)\n",
    "    \n",
    "                    #Calcula a nota PESQ\n",
    "                    try:\n",
    "                        pesq_score = pesq(8000, sound, noisy_sound, 'nb')\n",
    "                    except:\n",
    "                        continue\n",
    "    \n",
    "                    # valor_min = -0.6\n",
    "                    # valor_max = 4.6\n",
    "                    # pesq_score = (pesq_score - valor_min) / (valor_max - valor_min)\n",
    "                    \n",
    "                    A, phi, _, _ = calculate_stft_magnitude_and_phase(sound_escalado)\n",
    "                    A_noisy, phi_noisy, _, _ = calculate_stft_magnitude_and_phase(noisy_sound)\n",
    "                    \n",
    "                    # Monta o fasor normalizando a faze por Pi\n",
    "                    F = np.concatenate([A.reshape(A.shape[0], A.shape[1], 1), (phi.reshape(phi.shape[0], phi.shape[1], 1) / (2*np.pi)) + 0.5], axis=-1)\n",
    "                    F_noisy = np.concatenate([A_noisy.reshape(A_noisy.shape[0], A_noisy.shape[1], 1), (phi_noisy.reshape(phi_noisy.shape[0], phi_noisy.shape[1], 1) / (2*np.pi)) + 0.5], axis=-1)\n",
    "                    \n",
    "                    # Adiciona o exemplo ao lote de treinamento\n",
    "                    x_train.append(F_noisy)\n",
    "                    x_train.append(F)\n",
    "\n",
    "                    y_train.append(pesq_score)\n",
    "                    y_train.append(4.64)\n",
    "                    \n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "            x_train = np.array(x_train)\n",
    "            y_train = np.array(y_train).reshape(-1, 1)\n",
    "            \n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5f347a47-6e30-4cc1-96b0-e670aefb8d5a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_generator_train = DataGenerator(sound_base.train_X, sound_base.noise_sounds)\n",
    "data_generator_val = DataGenerator(sound_base.val_X, sound_base.noise_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aba0569e-7924-4d7e-b358-c1ddfc44f595",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(data_generator_train.generate_sample_completo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2f233ba5-cd54-4e9f-b4df-e91620367e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "628b713e-3052-4394-8721-73bed4f0b240",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom activation function\n",
    "def custom_activation(x):\n",
    "    return 3.6 * sigmoid(x) + 1.04\n",
    "\n",
    "# Define the PESQNet model\n",
    "def PESQNet(input_shape):\n",
    "    # Define the input layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    conv1 = Conv2D(filters=32, kernel_size=(5, 5), activation='relu', padding='same')(input_layer)\n",
    "    maxpool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(maxpool1)\n",
    "    maxpool2 = MaxPooling2D((2, 1))(conv2)\n",
    "\n",
    "    # Encoder CNN - assuming the use of multiple widths for convolutional kernels\n",
    "    cnn_branches = []\n",
    "    for w in [5, 3, 1]:  # Example widths\n",
    "        conv = Conv2D(filters=32, kernel_size=(w, w), activation='relu', padding='same')(maxpool2)\n",
    "        maxpool = MaxPooling2D((2, 2))(conv)\n",
    "        cnn_branches.append(maxpool)\n",
    "\n",
    "    # Concatenate all CNN branches\n",
    "    cnn_output = Concatenate()(cnn_branches)\n",
    "\n",
    "    # Aplicamos TimeDistributed para processar cada uma das \"timesteps\" 16x16 de forma independente\n",
    "    # Suponha que você quer reduzir o número de features antes da LSTM\n",
    "    # Reduzimos a dimensionalidade antes da LSTM para não sobrecarregar a quantidade de parâmetros\n",
    "    time_distributed_output = TimeDistributed(Dense(128, activation='relu'))(cnn_output) # (None, 16, 16, 128)\n",
    "    \n",
    "    # Agora ajustamos o tensor para ter a forma correta para o LSTM, que é (None, timesteps, features)\n",
    "    # Nesse caso, consideramos cada linha da \"imagem\" após a TimeDistributed como um timestep\n",
    "    reshape_to_lstm = Reshape((-1, 16 * 128))(time_distributed_output) # (None, 16, 16*128)\n",
    "    \n",
    "    # LSTM part\n",
    "    blstm = Bidirectional(LSTM(128, return_sequences=True))(reshape_to_lstm)\n",
    "\n",
    "    # Statistics over blocks - here we're assuming this operation is done post-LSTM\n",
    "    # For now, we'll just pass the output through to the fully connected layers\n",
    "    # Further implementation is required to actually compute statistics over blocks\n",
    "\n",
    "    # Fully connected layers\n",
    "    fc1 = Dense(128, activation='relu')(blstm)\n",
    "    fc2 = Dense(32, activation='relu')(fc1)\n",
    "    output_layer = Dense(1, activation=custom_activation)(fc2)\n",
    "\n",
    "    # Create the model\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb019929-286b-475e-88fc-ef3cc3d9cbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming input_shape is (Kin, W, 1) where Kin is the number of frequency bins and W is the number of time frames\n",
    "# We also need to define the number of blocks B which would be a hyperparameter\n",
    "input_shape = (128, 64, 2)  # Replace Kin and W with actual values\n",
    "\n",
    "# Get the PESQNet model\n",
    "model = PESQNet(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "19bb39d1-69c7-4de3-a239-ed968034222f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, 128, 64, 2)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 128, 64, 32)  1632        ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d_30 (MaxPooling2D  (None, 64, 32, 32)  0           ['conv2d_30[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 64, 32, 32)   9248        ['max_pooling2d_30[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_31 (MaxPooling2D  (None, 32, 32, 32)  0           ['conv2d_31[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 32, 32, 32)   25632       ['max_pooling2d_31[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 32, 32, 32)   9248        ['max_pooling2d_31[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 32, 32, 32)   1056        ['max_pooling2d_31[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_32 (MaxPooling2D  (None, 16, 16, 32)  0           ['conv2d_32[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_33 (MaxPooling2D  (None, 16, 16, 32)  0           ['conv2d_33[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_34 (MaxPooling2D  (None, 16, 16, 32)  0           ['conv2d_34[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 16, 16, 96)   0           ['max_pooling2d_32[0][0]',       \n",
      "                                                                  'max_pooling2d_33[0][0]',       \n",
      "                                                                  'max_pooling2d_34[0][0]']       \n",
      "                                                                                                  \n",
      " time_distributed_4 (TimeDistri  (None, 16, 16, 128)  12416      ['concatenate_6[0][0]']          \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " reshape_3 (Reshape)            (None, 16, 2048)     0           ['time_distributed_4[0][0]']     \n",
      "                                                                                                  \n",
      " bidirectional_4 (Bidirectional  (None, 16, 256)     2229248     ['reshape_3[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 16, 128)      32896       ['bidirectional_4[0][0]']        \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 16, 32)       4128        ['dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 16, 1)        33          ['dense_12[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,325,537\n",
      "Trainable params: 2,325,537\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model with a custom loss function\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')  # Replace 'mean_squared_error' with the actual PESQ loss function\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7125beb1-8542-44eb-ba45-8bd021ce7e16",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch 1\n",
      "251/251 [==============================] - 395s 2s/step - loss: 0.3897 - val_loss: 0.1336\n",
      "Epoch 2\n",
      "251/251 [==============================] - 391s 2s/step - loss: 0.1617 - val_loss: 0.0949\n",
      "Epoch 3\n",
      "251/251 [==============================] - 387s 2s/step - loss: 0.1373 - val_loss: 0.1141\n",
      "Epoch 4\n",
      "251/251 [==============================] - 385s 2s/step - loss: 0.1154 - val_loss: 0.0791\n",
      "Epoch 5\n",
      "251/251 [==============================] - 387s 2s/step - loss: 0.1157 - val_loss: 0.0817\n",
      "Epoch 6\n",
      "251/251 [==============================] - 391s 2s/step - loss: 0.1043 - val_loss: 0.1160\n",
      "Epoch 7\n",
      "251/251 [==============================] - 385s 2s/step - loss: 0.1112 - val_loss: 0.1209\n",
      "Epoch 8\n",
      "251/251 [==============================] - 391s 2s/step - loss: 0.0972 - val_loss: 0.1117\n",
      "Epoch 9\n",
      "251/251 [==============================] - 393s 2s/step - loss: 0.0928 - val_loss: 0.0750\n",
      "Epoch 10\n",
      "251/251 [==============================] - 390s 2s/step - loss: 0.0913 - val_loss: 0.0891\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "steps_per_epoch = len(sound_base.train_X) // batch_size\n",
    "\n",
    "print('Starting training')\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    # Gera um novo lote de validação para cada época\n",
    "    validation_batch = next(data_generator_val.generate_sample_completo(batch_size=batch_size))\n",
    "    x_val, y_val = validation_batch\n",
    "    \n",
    "    model.fit(data_generator_train.generate_sample_completo(batch_size=batch_size),\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val),\n",
    "              # callbacks=[PlotLossesCallback()]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f02f9152-f39d-4bf5-9348-714976139cba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Get the current datetime\n",
    "current_datetime = datetime.datetime.now()\n",
    "\n",
    "# Format the datetime as a string to use in the file name\n",
    "datetime_str = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "model.save('PESQNet-loss-0.0913-epochs-10-'+datetime_str+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e2f814-6c98-4257-9216-1139df21b74c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
