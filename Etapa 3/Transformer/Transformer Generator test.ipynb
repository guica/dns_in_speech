{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35bd943a-9827-4bf7-a4c4-a4e5d9030a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/tf/utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99fdf8e7-80a8-496b-84d8-8a1f328eb6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generators import NoisyTargetGenerator\n",
    "from sound import Sound\n",
    "import numpy as np\n",
    "\n",
    "from utils import calculate_stft_magnitude_and_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c746fc03-c254-4eff-9929-654c34928fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_shape_size = 8192\n",
    "ws = 255\n",
    "ol = 128\n",
    "input_shape = (128, 64, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89df82cc-dca8-4cb0-93dc-4305921b5253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Speech Files: 100%|██████████| 8179/8179 [00:05<00:00, 1471.99it/s]\n",
      "Loading Noise Files: 100%|██████████| 8137/8137 [00:05<00:00, 1401.75it/s]\n",
      "/tf/utils/sound.py:65: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  clean_sounds = [sound for sound in clean_sounds if sound != self.TOO_SHORT_ERROR]\n",
      "/tf/utils/sound.py:77: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  noise_sounds = [sound for sound in noise_sounds if sound != self.TOO_SHORT_ERROR]\n"
     ]
    }
   ],
   "source": [
    "sound_base = Sound('/tf/Dados/Vozes/', '/tf/Dados/Ruido/', base_shape_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49a05096-71de-4bc3-91c2-b7d412c74719",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerGenerator(NoisyTargetGenerator):\n",
    "    def __init__(self, sound_files, noise_files, block_size=2, normalize_phi=True):\n",
    "        super().__init__(sound_files, noise_files, block_size=block_size, normalize_phi=normalize_phi)\n",
    "\n",
    "    def generate_batch_transformer(self, clean_phasors):\n",
    "        \"\"\"\n",
    "        Generate a batch of transformed arrays and y_samples from clean and noisy phasors.\n",
    "    \n",
    "        :param clean_phasors: Numpy array of shape (128, 64, 2), representing the clean phasors.\n",
    "        :return: Tuple containing a list of 64 transformed arrays of shape (128, 128, 2) and an array y_samples of shape (64, 128, 1, 2).\n",
    "        \"\"\"\n",
    "    \n",
    "        # Criando um novo array com shape (128, 64, 2) com zeros\n",
    "        new_array = np.zeros((128, 64, 2))\n",
    "    \n",
    "        # Preenchendo o novo array com os valores do array clean_phasors\n",
    "        # new_array[:, :64, :] = clean_phasors\n",
    "    \n",
    "        # Inicializando a lista para armazenar os 64 arrays\n",
    "        arrays = []\n",
    "    \n",
    "        # Inicializando o array y_samples com o shape desejado (64, 128, 1, 2)\n",
    "        y_samples = np.zeros((64, 128, 1, 2))\n",
    "    \n",
    "        for i in range(64):\n",
    "            # Copiando o array new_array para um novo array temporário\n",
    "            temp_array = np.copy(new_array)\n",
    "            \n",
    "            # Substituindo os valores em temp_array pelos valores correspondentes de clean_phasors\n",
    "            if i != 0:\n",
    "                temp_array[:, :i, :] = clean_phasors[:, :i, :]\n",
    "    \n",
    "            # Adicionando o temp_array à lista\n",
    "            arrays.append(temp_array)\n",
    "    \n",
    "            # Preenchendo y_samples com os valores correspondentes de clean_phasors\n",
    "            y_samples[i, :, 0, :] = clean_phasors[:, i, :]\n",
    "    \n",
    "        return np.array(arrays), y_samples\n",
    "            \n",
    "        \n",
    "    \n",
    "    def generate_sample_completo(self, batch_size=32, include_clean=False):\n",
    "        while True:\n",
    "            # Carrega um lote de vozes e ruidos\n",
    "            sound_batch, noise_batch = self.pick_random_blocks(batch_size)\n",
    "\n",
    "            xn_train = []\n",
    "            xc_train = []\n",
    "            y_train = []\n",
    "            \n",
    "            # Adiciona ruído a cada som e calcula a nota PESQ\n",
    "            for sound, noise in zip(sound_batch, noise_batch):\n",
    "\n",
    "                sound_escalado, noisy_sound = self.normalize_and_add_noise(sound, noise)\n",
    "                \n",
    "                if sound_escalado is None or noisy_sound is None:\n",
    "                    continue\n",
    "                \n",
    "                # try:\n",
    "                A, phi, _, _ = calculate_stft_magnitude_and_phase(sound_escalado)\n",
    "                A_noisy, phi_noisy, _, _ = calculate_stft_magnitude_and_phase(noisy_sound)\n",
    "                # except:\n",
    "                #     continue\n",
    "\n",
    "                F = self.assemble_phasors(A, phi)\n",
    "                F_noisy = self.assemble_phasors(A_noisy, phi_noisy)\n",
    "\n",
    "                xc_samples, y_samples = self.generate_batch_transformer(F)\n",
    "                \n",
    "                # Adiciona os exemplos aos lotes de treinamento\n",
    "                for _ in range(64):\n",
    "                    xn_train.append(F_noisy)\n",
    "                xc_train.append(xc_samples)\n",
    "                y_train.append(y_samples)\n",
    "                \n",
    "                if include_clean:\n",
    "                    xc_samples, y_samples = self.generate_batch_transformer(F)\n",
    "                    for _ in range(64):\n",
    "                        xn_train.append(F)\n",
    "                    xc_train.append(xc_samples)\n",
    "                    y_train.append(y_samples)\n",
    "\n",
    "            xn_train = np.array(xn_train)\n",
    "            xc_train = np.array(xc_train)\n",
    "            y_train = np.array(y_train)\n",
    "            \n",
    "            yield [xn_train, xc_train.reshape(-1, 128, 64, 2)], y_train.reshape(-1, 128, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dba735e-417d-4011-a846-0bcf01ce857a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_train = TransformerGenerator(sound_base.train_X, sound_base.noise_sounds)\n",
    "data_generator_val = TransformerGenerator(sound_base.val_X, sound_base.noise_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "043c20e9-9787-46fc-95e8-3325ce24ad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Dense, Dropout, LayerNormalization\n",
    "from tensorflow.keras import Input, Model\n",
    "import tensorflow as tf\n",
    "\n",
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = Dense(d_model)\n",
    "        self.wk = Dense(d_model)\n",
    "        self.wv = Dense(d_model)\n",
    "\n",
    "        self.dense = Dense(d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)\n",
    "        k = self.wk(k)\n",
    "        v = self.wv(v)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)\n",
    "        k = self.split_heads(k, batch_size)\n",
    "        v = self.split_heads(v, batch_size)\n",
    "\n",
    "        scaled_attention_logits = tf.matmul(q, k, transpose_b=True)\n",
    "        scaled_attention_logits /= tf.math.sqrt(tf.cast(self.depth, tf.float32))\n",
    "\n",
    "        if mask is not None:\n",
    "            scaled_attention_logits += (mask * -1e9)\n",
    "\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "\n",
    "        output = tf.matmul(attention_weights, v)\n",
    "\n",
    "        output = tf.transpose(output, perm=[0, 2, 1, 3])\n",
    "        output = tf.reshape(output, (batch_size, -1, self.d_model))\n",
    "\n",
    "        return self.dense(output)\n",
    "\n",
    "# Agora, vamos construir as camadas de encoder e decoder usando a camada de MultiHeadAttention\n",
    "def encoder_layer(d_model, num_heads, dff, rate=0.1):\n",
    "    inputs = Input(shape=(None, d_model))\n",
    "    padding_mask = Input(shape=(1, 1, None))\n",
    "\n",
    "    attention = MultiHeadAttention(d_model, num_heads)(inputs, inputs, inputs, padding_mask)\n",
    "    attention = Dropout(rate)(attention)\n",
    "    attention = LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    outputs = Dense(dff, activation='relu')(attention)\n",
    "    outputs = Dense(d_model)(outputs)\n",
    "    outputs = Dropout(rate)(outputs)\n",
    "    outputs = LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return Model(inputs=[inputs, padding_mask], outputs=outputs, name=\"encoder_layer\")\n",
    "\n",
    "def decoder_layer(d_model, num_heads, dff, rate=0.1):\n",
    "    inputs = Input(shape=(None, d_model))\n",
    "    enc_outputs = Input(shape=(None, d_model))\n",
    "    look_ahead_mask = Input(shape=(1, None, None))\n",
    "    padding_mask = Input(shape=(1, 1, None))\n",
    "\n",
    "    attention1 = MultiHeadAttention(d_model, num_heads)(inputs, inputs, inputs, look_ahead_mask)\n",
    "    attention1 = Dropout(rate)(attention1)\n",
    "    attention1 = LayerNormalization(epsilon=1e-6)(inputs + attention1)\n",
    "\n",
    "    attention2 = MultiHeadAttention(d_model, num_heads)(enc_outputs, enc_outputs, attention1, padding_mask)\n",
    "    attention2 = Dropout(rate)(attention2)\n",
    "    attention2 = LayerNormalization(epsilon=1e-6)(attention1 + attention2)\n",
    "\n",
    "    outputs = Dense(dff, activation='relu')(attention2)\n",
    "    outputs = Dense(d_model)(outputs)\n",
    "    outputs = Dropout(rate)(outputs)\n",
    "    outputs = LayerNormalization(epsilon=1e-6)(attention2 + outputs)\n",
    "\n",
    "    return Model(inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask], outputs=outputs, name=\"decoder_layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db43d3a7-3794-4926-9a0a-c6dfb3bd9f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, MaxPooling2D, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "def getTransformerLayers(input_seq, target_seq):\n",
    "    # Parâmetros do modelo\n",
    "    num_layers = 2\n",
    "    d_model = 32\n",
    "    num_heads = 2\n",
    "    dff = 512\n",
    "    max_seq_len = 512\n",
    "    dropout_rate = 0.1\n",
    "    \n",
    "    # Função para criar uma única camada do Encoder\n",
    "    def single_encoder_layer(d_model, num_heads, dff, rate):\n",
    "        inputs = Input(shape=(None, d_model))\n",
    "        attention = MultiHeadAttention(d_model, num_heads)(inputs, inputs, inputs, None)\n",
    "        attention = Dropout(rate)(attention)\n",
    "        attention = LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "    \n",
    "        outputs = Dense(dff, activation='relu')(attention)\n",
    "        outputs = Dense(d_model)(outputs)\n",
    "        outputs = Dropout(rate)(outputs)\n",
    "        outputs = LayerNormalization(epsilon=1e-6)(attention + outputs)\n",
    "    \n",
    "        return Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # Função para criar uma única camada do Decoder\n",
    "    def single_decoder_layer(d_model, num_heads, dff, rate):\n",
    "        inputs = Input(shape=(None, d_model))\n",
    "        enc_outputs = Input(shape=(None, d_model))\n",
    "    \n",
    "        attention1 = MultiHeadAttention(d_model, num_heads)(inputs, inputs, inputs, None)\n",
    "        attention1 = Dropout(rate)(attention1)\n",
    "        attention1 = LayerNormalization(epsilon=1e-6)(inputs + attention1)\n",
    "    \n",
    "        attention2 = MultiHeadAttention(d_model, num_heads)(enc_outputs, enc_outputs, attention1, None)\n",
    "        attention2 = Dropout(rate)(attention2)\n",
    "        attention2 = LayerNormalization(epsilon=1e-6)(attention1 + attention2)\n",
    "    \n",
    "        outputs = Dense(dff, activation='relu')(attention2)\n",
    "        outputs = Dense(d_model)(outputs)\n",
    "        outputs = Dropout(rate)(outputs)\n",
    "        outputs = LayerNormalization(epsilon=1e-6)(attention2 + outputs)\n",
    "    \n",
    "        return Model(inputs=[inputs, enc_outputs], outputs=outputs)\n",
    "    \n",
    "    # Criando as camadas de Encoder e Decoder\n",
    "    encoder_layers = [single_encoder_layer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "    decoder_layers = [single_decoder_layer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "    \n",
    "    # Definindo as entradas do modelo\n",
    "    # input_seq = Input(shape=(max_seq_len, d_model))\n",
    "    # target_seq = Input(shape=(max_seq_len, d_model))\n",
    "    \n",
    "    # Construindo o Encoder\n",
    "    x = input_seq\n",
    "    for encoder_layer in encoder_layers:\n",
    "        x = encoder_layer(x)\n",
    "    encoder_output = x\n",
    "    \n",
    "    # Construindo o Decoder\n",
    "    y = target_seq\n",
    "    for decoder_layer in decoder_layers:\n",
    "        y = decoder_layer([y, encoder_output])\n",
    "    decoder_output = y\n",
    "    \n",
    "    # Camada de saída\n",
    "    final_output = Dense(d_model, activation='linear')(decoder_output)\n",
    "\n",
    "    return final_output\n",
    "# Criando o modelo Transformer\n",
    "# transformer = Model(inputs=[input_seq, target_seq], outputs=final_output)\n",
    "\n",
    "# Resumo do modelo\n",
    "# transformer.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5600c049-27c6-42ef-8d66-27e07c15ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_conv_layer(x, filter_size=3, size=32, dropout=0., batch_norm=False):\n",
    "        '''\n",
    "        construction of a double convolutional layer using\n",
    "        SAME padding\n",
    "        RELU nonlinear activation function\n",
    "        :param x: input\n",
    "        :param filter_size: size of convolutional filter\n",
    "        :param size: number of filters\n",
    "        :param dropout: FLAG & RATE of dropout.\n",
    "                if < 0 dropout cancelled, if > 0 set as the rate\n",
    "        :param batch_norm: flag of if batch_norm used,\n",
    "                if True batch normalization\n",
    "        :return: output of a double convolutional layer\n",
    "        '''\n",
    "\n",
    "        axis = 3\n",
    "        conv = tf.keras.layers.Conv2D(size, (filter_size, filter_size), padding='same')(x)\n",
    "        if batch_norm is True:\n",
    "            conv = tf.keras.layers.BatchNormalization(axis=axis)(conv)\n",
    "        conv = tf.keras.layers.Activation('relu')(conv)\n",
    "        conv = tf.keras.layers.Conv2D(size, (filter_size, filter_size), padding='same')(conv)\n",
    "        if batch_norm is True:\n",
    "            conv = tf.keras.layers.BatchNormalization(axis=axis)(conv)\n",
    "        conv = tf.keras.layers.Activation('relu')(conv)\n",
    "        if dropout > 0:\n",
    "            conv = tf.keras.layers.Dropout(dropout)(conv)\n",
    "\n",
    "        shortcut = tf.keras.layers.Conv2D(size, kernel_size=(1, 1), padding='same')(x)\n",
    "        if batch_norm is True:\n",
    "            shortcut = tf.keras.layers.BatchNormalization(axis=axis)(shortcut)\n",
    "\n",
    "        res_path = tf.keras.layers.add([shortcut, conv])\n",
    "        return res_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13a082ec-f081-458f-b422-f3396108ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(inputs):\n",
    "    FILTER_SIZE = 3\n",
    "    FILTER_NUM = 32\n",
    "    # Downsampling layers\n",
    "    # DownRes 1, double residual convolution + pooling\n",
    "    conv_128 = double_conv_layer(inputs, FILTER_SIZE, FILTER_NUM)\n",
    "    pool_64 = MaxPooling2D(pool_size=(2,2))(conv_128)\n",
    "    # DownRes 2\n",
    "    conv_64 = double_conv_layer(pool_64, FILTER_SIZE, 2*FILTER_NUM)\n",
    "    pool_32 = MaxPooling2D(pool_size=(2,2))(conv_64)\n",
    "    # DownRes 3\n",
    "    conv_32 = double_conv_layer(pool_32, FILTER_SIZE, 4*FILTER_NUM)\n",
    "    pool_16 = MaxPooling2D(pool_size=(2,2))(conv_32)\n",
    "    # DownRes 4\n",
    "    conv_16 = double_conv_layer(pool_16, FILTER_SIZE, 8*FILTER_NUM)\n",
    "    pool_8 = MaxPooling2D(pool_size=(2,2))(conv_16)\n",
    "    # DownRes 5, convolution only\n",
    "    conv_8 = double_conv_layer(pool_8, FILTER_SIZE, 16*FILTER_NUM)\n",
    "\n",
    "    return conv_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9abdb92-3384-413d-8c16-00e51090990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desembeding(inputs):\n",
    "    FILTER_SIZE = 3\n",
    "    FILTER_NUM = 32\n",
    "    UP_SAMP_SIZE = (2, 2)\n",
    "    axis = 3\n",
    "\n",
    "    # Upsampling layers\n",
    "    up_16 = tf.keras.layers.UpSampling2D(size=UP_SAMP_SIZE, data_format=\"channels_last\")(inputs)\n",
    "    up_conv_16 = double_conv_layer(up_16, FILTER_SIZE, 8*FILTER_NUM)\n",
    "\n",
    "    up_32 = tf.keras.layers.UpSampling2D(size=UP_SAMP_SIZE, data_format=\"channels_last\")(up_conv_16)\n",
    "    up_conv_32 = double_conv_layer(up_32, FILTER_SIZE, 4*FILTER_NUM)\n",
    "\n",
    "    up_64 = tf.keras.layers.UpSampling2D(size=UP_SAMP_SIZE, data_format=\"channels_last\")(up_conv_32)\n",
    "    up_conv_64 = double_conv_layer(up_64, FILTER_SIZE, 2*FILTER_NUM)\n",
    "\n",
    "    up_128 = tf.keras.layers.UpSampling2D(size=UP_SAMP_SIZE, data_format=\"channels_last\")(up_conv_64)\n",
    "    up_conv_128 = double_conv_layer(up_128, FILTER_SIZE, FILTER_NUM)\n",
    "\n",
    "    # Ajustando o shape para (128, 1, 2)\n",
    "    conv_final = tf.keras.layers.Conv2D(2, kernel_size=(64, 1), strides=(64, 1))(up_conv_128)\n",
    "    final = tf.keras.layers.Reshape((128, 1, 2))(conv_final)\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e150b86a-0547-49cd-a539-1981acd405ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy = Input((128, 64, 2))\n",
    "gen = Input((128, 64, 2))\n",
    "\n",
    "emb_noizy = embedding(noisy)\n",
    "emb_gen = embedding(gen)\n",
    "\n",
    "emb_noizy_reshape = Reshape((512, 32))(emb_noizy)\n",
    "emb_gen_reshape = Reshape((512, 32))(emb_gen)\n",
    "\n",
    "trasformer = getTransformerLayers(emb_noizy_reshape, emb_gen_reshape)\n",
    "emb_out = Reshape((8, 4, 512))(trasformer)\n",
    "\n",
    "output = desembeding(emb_out)\n",
    "\n",
    "model = Model(inputs=[noisy, emb_gen], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd4e10ff-e566-4457-9cff-ef31f770eefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 128, 64, 2)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 128, 64, 32)  608         ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 128, 64, 32)  0           ['conv2d_43[1][0]']              \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 128, 64, 32)  9248        ['activation_28[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 128, 64, 32)  96          ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 128, 64, 32)  0           ['conv2d_44[1][0]']              \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 128, 64, 32)  0           ['conv2d_45[1][0]',              \n",
      "                                                                  'activation_29[1][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 64, 32, 32)  0           ['add_14[1][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 64, 32, 64)   18496       ['max_pooling2d_8[1][0]']        \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 64, 32, 64)   0           ['conv2d_46[1][0]']              \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 64, 32, 64)   36928       ['activation_30[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 64, 32, 64)   2112        ['max_pooling2d_8[1][0]']        \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 64, 32, 64)   0           ['conv2d_47[1][0]']              \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 64, 32, 64)   0           ['conv2d_48[1][0]',              \n",
      "                                                                  'activation_31[1][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 32, 16, 64)  0           ['add_15[1][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 32, 16, 128)  73856       ['max_pooling2d_9[1][0]']        \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 32, 16, 128)  0           ['conv2d_49[1][0]']              \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 32, 16, 128)  147584      ['activation_32[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 32, 16, 128)  8320        ['max_pooling2d_9[1][0]']        \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 32, 16, 128)  0           ['conv2d_50[1][0]']              \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 32, 16, 128)  0           ['conv2d_51[1][0]',              \n",
      "                                                                  'activation_33[1][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 16, 8, 128)  0           ['add_16[1][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 16, 8, 256)   295168      ['max_pooling2d_10[1][0]']       \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 16, 8, 256)   0           ['conv2d_52[1][0]']              \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 16, 8, 256)   590080      ['activation_34[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 16, 8, 256)   33024       ['max_pooling2d_10[1][0]']       \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 16, 8, 256)   0           ['conv2d_53[1][0]']              \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 16, 8, 256)   0           ['conv2d_54[1][0]',              \n",
      "                                                                  'activation_35[1][0]']          \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 8, 4, 256)   0           ['add_17[1][0]']                 \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 8, 4, 512)    1180160     ['max_pooling2d_11[1][0]']       \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 8, 4, 512)    0           ['conv2d_55[1][0]']              \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 8, 4, 512)    2359808     ['activation_36[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 8, 4, 512)    131584      ['max_pooling2d_11[1][0]']       \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 8, 4, 512)    0           ['conv2d_56[1][0]']              \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 8, 4, 512)    0           ['conv2d_57[1][0]',              \n",
      "                                                                  'activation_37[1][0]']          \n",
      "                                                                                                  \n",
      " reshape_4 (Reshape)            (None, 512, 32)      0           ['add_18[1][0]']                 \n",
      "                                                                                                  \n",
      " input_24 (InputLayer)          [(None, 8, 4, 512)]  0           []                               \n",
      "                                                                                                  \n",
      " model_9 (Functional)           (None, None, 32)     37664       ['reshape_4[1][0]']              \n",
      "                                                                                                  \n",
      " reshape_5 (Reshape)            (None, 512, 32)      0           ['input_24[0][0]']               \n",
      "                                                                                                  \n",
      " model_10 (Functional)          (None, None, 32)     37664       ['model_9[1][0]']                \n",
      "                                                                                                  \n",
      " model_11 (Functional)          (None, None, 32)     41952       ['reshape_5[1][0]',              \n",
      "                                                                  'model_10[1][0]']               \n",
      "                                                                                                  \n",
      " model_12 (Functional)          (None, None, 32)     41952       ['model_11[1][0]',               \n",
      "                                                                  'model_10[1][0]']               \n",
      "                                                                                                  \n",
      " dense_97 (Dense)               (None, 512, 32)      1056        ['model_12[1][0]']               \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)            (None, 8, 4, 512)    0           ['dense_97[1][0]']               \n",
      "                                                                                                  \n",
      " up_sampling2d_4 (UpSampling2D)  (None, 16, 8, 512)  0           ['reshape_6[1][0]']              \n",
      "                                                                                                  \n",
      " conv2d_73 (Conv2D)             (None, 16, 8, 256)   1179904     ['up_sampling2d_4[1][0]']        \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 16, 8, 256)   0           ['conv2d_73[1][0]']              \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 16, 8, 256)   590080      ['activation_48[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 16, 8, 256)   131328      ['up_sampling2d_4[1][0]']        \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 16, 8, 256)   0           ['conv2d_74[1][0]']              \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 16, 8, 256)   0           ['conv2d_75[1][0]',              \n",
      "                                                                  'activation_49[1][0]']          \n",
      "                                                                                                  \n",
      " up_sampling2d_5 (UpSampling2D)  (None, 32, 16, 256)  0          ['add_24[1][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 32, 16, 128)  295040      ['up_sampling2d_5[1][0]']        \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 32, 16, 128)  0           ['conv2d_76[1][0]']              \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 32, 16, 128)  147584      ['activation_50[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 32, 16, 128)  32896       ['up_sampling2d_5[1][0]']        \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 32, 16, 128)  0           ['conv2d_77[1][0]']              \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 32, 16, 128)  0           ['conv2d_78[1][0]',              \n",
      "                                                                  'activation_51[1][0]']          \n",
      "                                                                                                  \n",
      " up_sampling2d_6 (UpSampling2D)  (None, 64, 32, 128)  0          ['add_25[1][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 64, 32, 64)   73792       ['up_sampling2d_6[1][0]']        \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 64, 32, 64)   0           ['conv2d_79[1][0]']              \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 64, 32, 64)   36928       ['activation_52[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 64, 32, 64)   8256        ['up_sampling2d_6[1][0]']        \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 64, 32, 64)   0           ['conv2d_80[1][0]']              \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 64, 32, 64)   0           ['conv2d_81[1][0]',              \n",
      "                                                                  'activation_53[1][0]']          \n",
      "                                                                                                  \n",
      " up_sampling2d_7 (UpSampling2D)  (None, 128, 64, 64)  0          ['add_26[1][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 128, 64, 32)  18464       ['up_sampling2d_7[1][0]']        \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 128, 64, 32)  0           ['conv2d_82[1][0]']              \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 128, 64, 32)  9248        ['activation_54[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 128, 64, 32)  2080        ['up_sampling2d_7[1][0]']        \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 128, 64, 32)  0           ['conv2d_83[1][0]']              \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 128, 64, 32)  0           ['conv2d_84[1][0]',              \n",
      "                                                                  'activation_55[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 2, 64, 2)     4098        ['add_27[1][0]']                 \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)            (None, 128, 1, 2)    0           ['conv2d_85[1][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 7,577,058\n",
      "Trainable params: 7,577,058\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40c45279-e46c-49b8-8e4d-ac7a765cd4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='msle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "729c9636-ee31-4328-a0b2-a0d3e2041bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch 1\n",
      " 1300/16114 [=>............................] - ETA: 2:18:34 - loss: 0.1680"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m validation_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_generator_val\u001b[38;5;241m.\u001b[39mgenerate_sample_completo(batch_size\u001b[38;5;241m=\u001b[39mbatch_size))\n\u001b[1;32m     11\u001b[0m [x1_val, x2_val], y_val \u001b[38;5;241m=\u001b[39m validation_batch\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_generator_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_sample_completo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_clean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx1_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2_val\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 2\n",
    "steps_per_epoch = len(sound_base.train_X) // batch_size\n",
    "\n",
    "print('Starting training')\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    # Gera um novo lote de validação para cada época\n",
    "    validation_batch = next(data_generator_val.generate_sample_completo(batch_size=batch_size))\n",
    "    [x1_val, x2_val], y_val = validation_batch\n",
    "    \n",
    "    model.fit(data_generator_train.generate_sample_completo(batch_size=batch_size, include_clean=False),\n",
    "                     steps_per_epoch=steps_per_epoch,\n",
    "                     epochs=1,\n",
    "                     validation_data=([x1_val, x2_val], y_val),\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565de0b5-3770-4dfb-86da-534fdb8c6560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
