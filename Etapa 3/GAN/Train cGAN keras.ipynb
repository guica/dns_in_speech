{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89a1a67-cfc4-4c13-970c-fff2554985e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/tf/utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8dd13df-1a11-48f6-a0ad-e8c9397c33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be6817c1-2706-4c18-9f04-ad386d3ebe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dropout, Conv2DTranspose, ReLU, ZeroPadding2D, BatchNormalization, Input, Conv2D, Conv2DTranspose, Flatten, Dense, LeakyReLU, MaxPooling2D, UpSampling2D, Concatenate, concatenate\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import calculate_snr, itakura_distortion, somar_sinais, add_white_gaussian_noise, performance\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sound import Sound\n",
    "\n",
    "from IPython.display import Audio\n",
    "import time\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e877227-d2f2-4e27-a3ed-18694fbcc058",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_shape_size = 8192\n",
    "ws = 255\n",
    "ol = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f05a93cf-ea18-4f95-9626-bdeda3b2d0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading clean files: 100%|██████████| 5476/5476 [00:03<00:00, 1815.43it/s]\n",
      "Loading noise files: 100%|██████████| 2000/2000 [00:10<00:00, 188.39it/s]\n"
     ]
    }
   ],
   "source": [
    "sound_base = Sound('../../Dados/Base/', '../../Dados/ESC-50-master/audio/', base_shape_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "890c326b-ac14-44f2-9708-dd3068c329b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stft_magnitude_and_phase(signal, sampling_rate=8000, window_size=ws, overlap=ol):\n",
    "    # Calcula a STFT usando a biblioteca librosa\n",
    "    stft_result = librosa.stft(signal, n_fft=window_size, hop_length=overlap)\n",
    "    \n",
    "    magnitude, phase = librosa.magphase(stft_result)\n",
    "    phi = np.angle(phase)\n",
    "    f = librosa.fft_frequencies(sr=sampling_rate, n_fft=window_size)\n",
    "    t = librosa.frames_to_time(np.arange(stft_result.shape[1]), sr=sampling_rate, hop_length=overlap)\n",
    "\n",
    "    return magnitude, phi, f, t\n",
    "\n",
    "def reconstruct_signal_from_stft(magnitude, phi, sampling_rate=8000, window_size=ws, overlap=ol):\n",
    "    # Reconstruct the signal from magnitude and phase\n",
    "    complex_spec = magnitude * np.exp(1j * phi)\n",
    "    signal = librosa.istft(complex_spec, hop_length=overlap)\n",
    "\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "539a0b5d-83f8-4044-b862-9fbf154aa607",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, sound_files, noise_files):\n",
    "        self.sound_files = sound_files\n",
    "        self.noise_files = noise_files\n",
    "\n",
    "    def generate_sample_completo(self, batch_size=32):\n",
    "        while True:\n",
    "            # Carrega um lote de sons\n",
    "            sound_batch_choices = np.random.choice(self.sound_files.shape[0], size=batch_size, replace=False)\n",
    "            sound_batch = self.sound_files[sound_batch_choices]\n",
    "            \n",
    "            # Carrega um lote de ruídos\n",
    "            noise_batch_choices = np.random.choice(self.noise_files.shape[0], size=batch_size, replace=False)\n",
    "            noise_batch = self.noise_files[noise_batch_choices]\n",
    "            \n",
    "            x_train = []\n",
    "            y_train = []\n",
    "            \n",
    "            # Adiciona ruído a cada som e calcula a nota PESQ\n",
    "            for sound, noise in zip(sound_batch, noise_batch):\n",
    "                # noisy_sound = somar_sinais(sound, noise, sr)\n",
    "                min_valor = np.min(sound)\n",
    "                max_valor = np.max(sound)\n",
    "                \n",
    "                # Defina o novo intervalo desejado\n",
    "                novo_min = -0.4\n",
    "                novo_max = 0.4\n",
    "                \n",
    "                # Realize a escala do sinal para o novo intervalo\n",
    "                sound_escalado = (sound - min_valor) / (max_valor - min_valor) * (novo_max - novo_min) + novo_min\n",
    "\n",
    "                sr = np.random.randint(0, 20, size=(1,)[0])\n",
    "                noisy_sound = somar_sinais(sound_escalado, noise, sr)\n",
    "                \n",
    "                # noisy_sound = add_white_gaussian_noise(noisy_sound, np.random.randint(20, 30, size=(1,)[0]))\n",
    "                noisy_sound = add_white_gaussian_noise(noisy_sound, np.random.randint(20, 30, size=(1,)[0]))\n",
    "                noisy_sound = np.clip(noisy_sound, -1.0, 1.0)\n",
    "                \n",
    "                A, phi, _, _ = calculate_stft_magnitude_and_phase(sound_escalado)\n",
    "                A_noisy, phi_noisy, _, _ = calculate_stft_magnitude_and_phase(noisy_sound)\n",
    "\n",
    "                # A /= NORM_FACTOR\n",
    "                # A_noisy /= NORM_FACTOR\n",
    "\n",
    "                # A = 10*np.log10(A)\n",
    "                # A_noisy = 10*np.log10(A_noisy)\n",
    "\n",
    "                # xA_batch.append(A)\n",
    "                # xphi_batch.append(phi)\n",
    "                # yA_batch.append(A_noisy)\n",
    "                # yphi_batch.append(phi_noisy)\n",
    "                \n",
    "                # Monta o fasor normalizando a faze por Pi\n",
    "                F = np.concatenate([A.reshape(A.shape[0], A.shape[1], 1), (phi.reshape(phi.shape[0], phi.shape[1], 1) / (2*np.pi)) + 0.5], axis=-1)\n",
    "                F_noisy = np.concatenate([A_noisy.reshape(A_noisy.shape[0], A_noisy.shape[1], 1), (phi_noisy.reshape(phi_noisy.shape[0], phi_noisy.shape[1], 1) / (2*np.pi)) + 0.5], axis=-1)\n",
    "                \n",
    "                # Adiciona o exemplo ao lote de treinamento\n",
    "                x_train.append(F_noisy)\n",
    "                y_train.append(F)\n",
    "\n",
    "            x_train = np.array(x_train)\n",
    "            y_train = np.array(y_train)\n",
    "            \n",
    "            yield x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "734548ee-55f1-456a-b14e-fdd693e5f79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator_train = DataGenerator(sound_base.train_X, sound_base.noise_sounds)\n",
    "data_generator_val = DataGenerator(sound_base.val_X, sound_base.noise_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "032c921e-9acd-42aa-92ef-47b7cfdd14ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "    result = tf.keras.Sequential()\n",
    "    result.add(Conv2D(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "    if apply_batchnorm:\n",
    "        result.add(BatchNormalization())\n",
    "\n",
    "    result.add(LeakyReLU())\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abee3029-99fa-43d3-8c2b-1e9349739c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(filters, size, apply_dropout=False):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(Conv2DTranspose(filters, size, strides=2, padding='same', kernel_initializer=initializer, use_bias=False))\n",
    "\n",
    "  result.add(BatchNormalization())\n",
    "\n",
    "  if apply_dropout:\n",
    "      result.add(Dropout(0.5))\n",
    "\n",
    "  result.add(ReLU())\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aeb3918e-ebdf-47d5-83c7-7c0205082dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para criar o gerador\n",
    "def Generator(inputs):\n",
    "    down_stack = [\n",
    "    downsample(64, 4, apply_batchnorm=False),  # (batch_size, 128, 128, 64)\n",
    "    downsample(128, 4),  # (batch_size, 64, 64, 128)\n",
    "    downsample(256, 4),  # (batch_size, 32, 32, 256)\n",
    "    downsample(512, 4),  # (batch_size, 16, 16, 512)\n",
    "    downsample(512, 4),  # (batch_size, 8, 8, 512)\n",
    "    # downsample(512, 4),  # (batch_size, 4, 4, 512)\n",
    "    # downsample(512, 4),  # (batch_size, 2, 2, 512)\n",
    "    # downsample(512, 4),  # (batch_size, 1, 1, 512)\n",
    "    ]\n",
    "    \n",
    "    up_stack = [\n",
    "    # upsample(512, 4, apply_dropout=True),  # (batch_size, 2, 2, 1024)\n",
    "    # upsample(512, 4, apply_dropout=True),  # (batch_size, 4, 4, 1024)\n",
    "    # upsample(512, 4, apply_dropout=True),  # (batch_size, 8, 8, 1024)\n",
    "    upsample(512, 4),  # (batch_size, 16, 16, 1024)\n",
    "    upsample(256, 4),  # (batch_size, 32, 32, 512)\n",
    "    upsample(128, 4),  # (batch_size, 64, 64, 256)\n",
    "    upsample(64, 4),  # (batch_size, 128, 128, 128)\n",
    "    ]\n",
    "    \n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    last = Conv2DTranspose(2, 4,\n",
    "                         strides=2,\n",
    "                         padding='same',\n",
    "                         kernel_initializer=initializer,\n",
    "                         activation='linear')  # (batch_size, 256, 256, 3)\n",
    "    \n",
    "    x = inputs\n",
    "    \n",
    "    # Downsampling through the model\n",
    "    skips = []\n",
    "    for down in down_stack:\n",
    "        x = down(x)\n",
    "        skips.append(x)\n",
    "        \n",
    "    skips = reversed(skips[:-1])\n",
    "    \n",
    "    # Upsampling and establishing the skip connections\n",
    "    for up, skip in zip(up_stack, skips):\n",
    "        x = up(x)\n",
    "        x = Concatenate()([x, skip])\n",
    "    \n",
    "    x = last(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Função para criar o discriminador\n",
    "def Discriminator(inputs, targets):\n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    \n",
    "    x = concatenate([inputs, targets])  # (batch_size, 256, 256, channels*2)\n",
    "    \n",
    "    down1 = downsample(64, 4, False)(x)  # (batch_size, 128, 128, 64)\n",
    "    down2 = downsample(128, 4)(down1)  # (batch_size, 64, 64, 128)\n",
    "    down3 = downsample(256, 4)(down2)  # (batch_size, 32, 32, 256)\n",
    "    \n",
    "    zero_pad1 = ZeroPadding2D()(down3)  # (batch_size, 34, 34, 256)\n",
    "    conv = Conv2D(512, 4, strides=1, kernel_initializer=initializer, use_bias=False)(zero_pad1) # (batch_size, 31, 31, 512)\n",
    "    \n",
    "    batchnorm1 = BatchNormalization()(conv)\n",
    "    \n",
    "    leaky_relu = LeakyReLU()(batchnorm1)\n",
    "    \n",
    "    zero_pad2 = ZeroPadding2D()(leaky_relu)  # (batch_size, 33, 33, 512)\n",
    "    \n",
    "    last = Conv2D(1, 4, strides=1, kernel_initializer=initializer)(zero_pad2)  # (batch_size, 30, 30, 1)\n",
    "    \n",
    "    return last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e9e15f2-d61e-46e6-8053-5ad971b11c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_input, tar):\n",
    "    prediction = model(test_input, training=True)\n",
    "    plt.figure(figsize=(22, 7))\n",
    "    \n",
    "    display_list = [test_input[0], tar[0], prediction[0]]\n",
    "    title = ['Log Power Spectrum - Som ruidoso', 'Log Power Spectrum - Som original', 'Log Power Spectrum - Som filtrado']\n",
    "    \n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        plt.title(title[i])\n",
    "        # Getting the pixel values in the [0, 1] range to plot.\n",
    "        plt.imshow(10 * np.log10(display_list[i][..., 0]), aspect='auto', cmap='inferno')\n",
    "        plt.colorbar(format='%+2.0f dB')  # Removi a variável 'im' e 'axs[0]'\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8311f54c-7639-4744-818e-8a16987071fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construindo o gerador e o discriminador\n",
    "input_shape = (128, 64, 2)\n",
    "\n",
    "disc_inputs = Input(shape=input_shape)\n",
    "target_inputs = Input(shape=input_shape)\n",
    "\n",
    "disc_out = Discriminator(disc_inputs, target_inputs)\n",
    "discriminator = Model([disc_inputs, target_inputs], disc_out, name='discriminator')\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=2e-4, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dee31175-17ed-419e-9387-7a16414be12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_inputs = Input(shape=input_shape)\n",
    "\n",
    "gen_output = Generator(gen_inputs)\n",
    "generator = Model(gen_inputs, gen_output, name='generator')\n",
    "generator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=2e-4, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e859ee3-3377-46e4-aa6f-e8663e86a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_input = Input(shape=input_shape)\n",
    "gan_target_inputs = Input(shape=input_shape)\n",
    "\n",
    "gen_outputs = generator(gan_input)\n",
    "gan_out = discriminator([gen_outputs, gan_target_inputs])\n",
    "gan = Model([gan_input, gan_target_inputs], gan_out, name='gan')\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=2e-4, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b42e80f4-3cdb-4bd5-bc8a-c8b39bf6569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4e0952-5157-4051-952a-e66b1206bbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamanho do lote\n",
    "batch_size = 64\n",
    "\n",
    "# Número de épocas e lotes por época\n",
    "num_epochs = 2\n",
    "num_batches_per_epoch = len(sound_base.train_X) // batch_size\n",
    "\n",
    "gan_loss = 1.\n",
    "diff_param = 10.\n",
    "SAME_ITS = 4\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    factor_dis = 1\n",
    "    factor_gen = 1\n",
    "    dis_loss_count = 0\n",
    "    gen_loss_count = 0\n",
    "    same_count = 0\n",
    "\n",
    "    for batch in tqdm(range(num_batches_per_epoch)):\n",
    "        # Restaurar o treinamento do discriminador\n",
    "        discriminator.trainable = True\n",
    "        generator.trainable = False\n",
    "\n",
    "        if discriminator_loss == 0. or (gan_loss / discriminator_loss) > diff_param:\n",
    "            gen_loss_count += 1\n",
    "            dis_loss_count = 0\n",
    "            factor_dis = 1\n",
    "            factor_gen = min(2 ** gen_loss_count, 128)\n",
    "\n",
    "        elif gan_loss == 0. or (discriminator_loss / gan_loss) > diff_param:\n",
    "            dis_loss_count += 1\n",
    "            gen_loss_count = 0\n",
    "            factor_dis = min(2 ** dis_loss_count, 128)\n",
    "            factor_gen = 1\n",
    "\n",
    "        else:\n",
    "            dis_loss_count = 0\n",
    "            gen_loss_count = 0\n",
    "            factor_dis = 1\n",
    "            factor_gen = 1\n",
    "\n",
    "            same_count += 1\n",
    "\n",
    "            if same_count % SAME_ITS == 0:\n",
    "                diff_param /= 2.\n",
    "                same_count = 0\n",
    "\n",
    "\n",
    "        print(f'Training Discriminator: {factor_dis} times\\nTraining Generator: {factor_gen} times')\n",
    "        \n",
    "        for i in range(factor_dis):\n",
    "            # Treinar o discriminador com dados reais\n",
    "            noisy_stft_batch, real_stft_batch = next(data_generator_train.generate_sample_completo(batch_size))\n",
    "            discriminator_loss_real = discriminator.train_on_batch([noisy_stft_batch, real_stft_batch], np.ones((14, 6, 1)))\n",
    "        \n",
    "            # Gerar dados falsos e treinar o discriminador com eles\n",
    "            generated_stft = generator.predict(noisy_stft_batch, verbose=False)\n",
    "            discriminator_loss_fake = discriminator.train_on_batch([noisy_stft_batch, generated_stft], np.zeros((14, 6, 1)))\n",
    "\n",
    "            discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
    "            print(f'Discriminator: {i + 1}/{factor_dis} - Loss fake: {discriminator_loss_fake:.5g} Loss real: {discriminator_loss_real:.5g}')\n",
    "\n",
    "        # Definir o discriminador como não treinável\n",
    "        discriminator.trainable = False\n",
    "        generator.trainable = True\n",
    "\n",
    "        for i in range(factor_gen):\n",
    "            noisy_stft_batch, _ = next(data_generator_train.generate_sample_completo(batch_size))\n",
    "            # Treinar a GAN com dados ruidosos (ruído) e rótulos de 1 (indicando que são dados reais)\n",
    "            gan_loss = gan.train_on_batch(noisy_stft_batch, np.ones((batch_size, 1)))\n",
    "            print(f'Generator: {i + 1}/{factor_gen} - Generator loss: {gan_loss}')\n",
    "\n",
    "        print('\\n\\n')\n",
    "\n",
    "    # Imprima métricas de treinamento ao final de cada época, se desejar\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Discriminator Loss: {discriminator_loss}, GAN Loss: {gan_loss}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
