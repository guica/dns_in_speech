{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe46ef64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.3.0)\n",
      "Requirement already satisfied: glob2 in /usr/local/lib/python3.8/dist-packages (0.7)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.65.0)\n",
      "Requirement already satisfied: pesq in /usr/local/lib/python3.8/dist-packages (0.0.4)\n",
      "Collecting pystoi\n",
      "  Downloading pystoi-0.3.3.tar.gz (7.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.10.1)\n",
      "Building wheels for collected packages: pystoi\n",
      "  Building wheel for pystoi (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pystoi: filename=pystoi-0.3.3-py2.py3-none-any.whl size=7779 sha256=84313a235eeab87a254aeda2d27909554972d888c4cd5393a6a4617231a4b80e\n",
      "  Stored in directory: /root/.cache/pip/wheels/62/35/75/c07f0861a60fb8aacf44fdd5c8c214a224a6c9edb4a4e1402f\n",
      "Successfully built pystoi\n",
      "Installing collected packages: pystoi\n",
      "Successfully installed pystoi-0.3.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/tf/utils/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4beed82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Definir o nível de log do TensorFlow para ERROR\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv1D, Activation, Dropout, Conv1D, Conv1DTranspose, MaxPooling1D, concatenate, Concatenate, LSTM, Dense, SimpleRNN, BatchNormalization, Dropout, BatchNormalization, Add, Flatten, UpSampling1D, UpSampling2D\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import LayerNormalization, Dropout, MultiHeadAttention, Conv2D, Conv2DTranspose, MaxPooling2D, Permute, Reshape, AveragePooling2D, GlobalAveragePooling2D, multiply, GlobalAveragePooling1D, Multiply\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "# import sounddevice as sd\n",
    "from scipy.signal import butter, filtfilt, stft, istft\n",
    "from scipy.signal import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "from glob2 import glob\n",
    "from tqdm import tqdm\n",
    "from pesq import pesq\n",
    "from pystoi import stoi\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "\n",
    "from utils import load_wav, generate_white_gaussian_noise, add_white_gaussian_noise, undersample_signal_with_antialiasing, somar_sinais, calculate_snr, save_sound_to_wav\n",
    "import matplotlib.pyplot as plt\n",
    "from sound import Sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa52f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_shape_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6941d12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading clean files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5476/5476 [00:02<00:00, 2128.72it/s]\n",
      "Loading noise files: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:09<00:00, 211.30it/s]\n"
     ]
    }
   ],
   "source": [
    "sound_base = Sound('./Base/', './ESC-50-master/audio/', base_shape_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12557ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_componentes_fourier(sinal):\n",
    "    if len(sinal.shape) == 3 and sinal.shape[2] == 1:\n",
    "        sinal = sinal.reshape(sinal.shape[0], sinal.shape[1])\n",
    "\n",
    "    componentes = np.fft.fft(sinal)\n",
    "    # Obter a magnitude máxima dos componentes\n",
    "    # max_magnitude = np.max(np.abs(componentes), axis=1).reshape(-1, 1)\n",
    "    # Normalizar os componentes para o intervalo [-1, 1]\n",
    "    max_magnitude = 1\n",
    "    # componentes_normalizados = componentes / max_magnitude\n",
    "    res = np.stack((np.real(componentes), np.imag(componentes)), axis=-1)\n",
    "\n",
    "    return np.array(res), max_magnitude\n",
    "\n",
    "def reconstruir_sinal(componentes, max_magnitude):\n",
    "    comp = componentes[:, :, 0] + 1j * componentes[:, :, 1]\n",
    "#     print(comp.shape)\n",
    "    sinal_reconstruido = np.fft.ifft(comp) * max_magnitude\n",
    "    return np.real(sinal_reconstruido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83a0a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, sound_files, noise_files):\n",
    "        self.sound_files = sound_files\n",
    "        self.noise_files = noise_files\n",
    "        self.MIN_NOISE_LEVEL = 5\n",
    "        self.MAX_NOISE_LEVEL = 30\n",
    "        \n",
    "        self.model_pre = load_model('modelo-pre-fourier-09-06-2023.h5')\n",
    "\n",
    "    def generate_sample_pesq(self, batch_size=32):\n",
    "        while True:\n",
    "            # Carrega um lote de sons\n",
    "            sound_batch_choices = np.random.choice(self.sound_files.shape[0], size=batch_size, replace=False)\n",
    "            sound_batch = self.sound_files[sound_batch_choices]\n",
    "            \n",
    "            # Carrega um lote de ruídos\n",
    "            noise_batch_choices = np.random.choice(self.noise_files.shape[0], size=batch_size, replace=False)\n",
    "            noise_batch = self.noise_files[noise_batch_choices]\n",
    "            \n",
    "            x_train = []\n",
    "            y_train = []\n",
    "            \n",
    "            # Adiciona ruído a cada som e calcula a nota PESQ\n",
    "            for sound, noise in zip(sound_batch, noise_batch):\n",
    "#                 sound = self.normalize_array(sound)\n",
    "#                 noise = self.normalize_array(noise)\n",
    "                \n",
    "                sr = np.random.randint(-5, 90, size=(1,)[0])\n",
    "                noisy_sound = somar_sinais(sound, noise, sr)\n",
    "#                 noisy_sound = self.normalize_array(noisy_sound)\n",
    "                \n",
    "                noisy_sound = add_white_gaussian_noise(noisy_sound, np.random.randint(7, 90, size=(1,)[0]))\n",
    "                noisy_sound = np.clip(noisy_sound, -1, 1)\n",
    "#                 noisy_sound = self.normalize_array(noisy_sound)\n",
    "\n",
    "                comp, _ = calcular_componentes_fourier(noisy_sound.reshape(-1, base_shape_size))\n",
    "                original_sound, _ = calcular_componentes_fourier(sound.reshape(-1, base_shape_size))\n",
    "\n",
    "                filtered = self.model_pre.predict(comp.reshape(-1, base_shape_size, 2), verbose=0)\n",
    "                filtered_sound = reconstruir_sinal(filtered, 1)\n",
    "                \n",
    "#                 print(sound.shape)\n",
    "#                 print(noisy_sound.shape)\n",
    "#                 print(comp.shape)\n",
    "#                 print(original_sound.shape)\n",
    "#                 print(filtered.shape)\n",
    "#                 print(filtered_sound.shape)\n",
    "                \n",
    "                \n",
    "                # Calcula a nota PESQ\n",
    "                try:\n",
    "                    pesq_score = pesq(8000, sound, filtered_sound.reshape(-1), 'nb')\n",
    "                except:\n",
    "                    continue\n",
    "                valor_min = -0.6\n",
    "                valor_max = 4.6\n",
    "                pesq_score = (pesq_score - valor_min) / (valor_max - valor_min)\n",
    "                \n",
    "                # Formata dados para treinamento\n",
    "#                 original_sound = sound #.reshape((base_shape_size, 1))\n",
    "#                 d_sound = noisy_sound #.reshape((base_shape_size, 1))\n",
    "                \n",
    "#                 comp, mmm = calcular_componentes_fourier(r_noisy_sound)\n",
    "#                 filtered = modelo_pre.predict(comp.reshape(-1, base_shape_size, 2))\n",
    "                \n",
    "#                 original_sound, ms = calcular_componentes_fourier(original_sound)\n",
    "#                 d_sound, md = calcular_componentes_fourier(d_sound)\n",
    "                \n",
    "#                 # Formata dados para treinamento\n",
    "#                 original_sound = sound.reshape((base_shape_size, 1))\n",
    "#                 d_sound = noisy_sound.reshape((base_shape_size, 1))\n",
    "                \n",
    "                merged_array = np.concatenate((original_sound.reshape(base_shape_size, 2), filtered.reshape(base_shape_size, 2)), axis=-1)\n",
    "#                 print(merged_array.shape)\n",
    "                # Adiciona o exemplo ao lote de treinamento\n",
    "                x_train.append(merged_array)\n",
    "                y_train.append(pesq_score)\n",
    "            \n",
    "            yield np.array(x_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491190f9",
   "metadata": {},
   "source": [
    "## Modelo para a PESQ\n",
    "\n",
    "1. Uma função `cnn()` é definida para construir a arquitetura do modelo CNN.\n",
    "2. O modelo é criado chamando `cnn()`, e um resumo do modelo é impresso.\n",
    "3. Instâncias de `DataGenerator` são criadas para os dados de treinamento e validação.\n",
    "4. O modelo é compilado com o otimizador 'adam' e a função de perda 'mse' (erro quadrático médio).\n",
    "5. Parâmetros de treinamento são definidos, como tamanho do lote e etapas por época.\n",
    "6. O treinamento começa com um loop que itera três vezes para três épocas.\n",
    "7. Para cada época, um novo lote de validação é gerado usando o gerador de dados de validação.\n",
    "8. O modelo é treinado usando o gerador de dados de treinamento, com as etapas por época, épocas, dados de validação e um callback para visualização de perda.\n",
    "9. Após o treinamento, o modelo é salvo em um arquivo chamado 'pesq-generator-16.h5'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b430d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn(input_layer, kernel_size=3):\n",
    "    # Define the input shape\n",
    "#     input_shape = (base_shape_size, 2)\n",
    "\n",
    "    # Define the model architecture\n",
    "#     input_layer = Input(shape=input_shape)\n",
    "\n",
    "    conv1 = Conv1D(16, kernel_size, activation='relu')(input_layer)\n",
    "    conv1 = Conv1D(16, kernel_size, activation='relu')(conv1)\n",
    "    pool1 = MaxPooling1D(pool_size=2)(conv1)\n",
    "\n",
    "    conv2 = Conv1D(32, kernel_size, activation='relu')(pool1)\n",
    "    conv2 = Conv1D(32, kernel_size, activation='relu')(conv2)\n",
    "    pool2 = MaxPooling1D(pool_size=2)(conv2)\n",
    "    \n",
    "    conv3 = Conv1D(64, kernel_size, activation='relu')(pool2)\n",
    "    conv3 = Conv1D(64, kernel_size, activation='relu')(conv3)\n",
    "    pool3 = MaxPooling1D(pool_size=2)(conv3)\n",
    "\n",
    "    conv4 = Conv1D(128, kernel_size, activation='relu')(pool3)\n",
    "    conv4 = Conv1D(128, kernel_size, activation='relu')(conv4)\n",
    "    pool4 = MaxPooling1D(pool_size=2)(conv4)\n",
    "    \n",
    "    conv5 = Conv1D(256, kernel_size, activation='relu')(pool4)\n",
    "    conv5 = Conv1D(256, kernel_size, activation='relu')(conv5)\n",
    "    pool5 = MaxPooling1D(pool_size=2)(conv4)\n",
    "    \n",
    "    conv6 = Conv1D(512, kernel_size, activation='relu')(pool5)\n",
    "    conv6 = Conv1D(512, kernel_size, activation='relu')(conv6)\n",
    "    pool6 = MaxPooling1D(pool_size=2)(conv6)\n",
    "\n",
    "    flatten = Flatten()(pool6)\n",
    "    dense1 = Dense(256, activation='relu')(flatten)\n",
    "    dense1 = Dense(256, activation='relu')(dense1)\n",
    "#     output_layer = Dense(1, activation='sigmoid')(dense1)\n",
    "\n",
    "#     model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return dense1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a3dcbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie uma instância do DataGenerator\n",
    "data_generator_train = DataGenerator(sound_base.train_X, sound_base.noise_sounds)\n",
    "data_generator_val = DataGenerator(sound_base.val_X, sound_base.noise_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92d6b4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (base_shape_size, 4)\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "in1 = cnn(input_layer, kernel_size=3)\n",
    "# in2 = cnn(input_layer, kernel_size=9)\n",
    "# in3 = cnn(input_layer, kernel_size=17)\n",
    "# in4 = cnn(input_layer, kernel_size=35)\n",
    "# in5 = cnn(input_layer, kernel_size=71)\n",
    "# in6 = cnn(input_layer, kernel_size=143)\n",
    "\n",
    "# den = concatenate([in1, in2, in3, in4])\n",
    "# den = concatenate([in1, in6])\n",
    "\n",
    "# output = Dense(128, activation='relu')(in1)\n",
    "# output = Dense(64, activation='relu')(output)\n",
    "\n",
    "output_layer = Dense(1, activation='sigmoid')(in1)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0d6f7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2000, 4)]         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 1998, 16)          208       \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1996, 16)          784       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 998, 16)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 996, 32)           1568      \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 994, 32)           3104      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 497, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 495, 64)           6208      \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 493, 64)           12352     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 246, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 244, 128)          24704     \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 242, 128)          49280     \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 121, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 119, 512)          197120    \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 117, 512)          786944    \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 58, 512)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 29696)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               7602432   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,750,753\n",
      "Trainable params: 8,750,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56f528bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('chech.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a970d996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "Epoch 1\n",
      "254/254 [==============================] - 2009s 8s/step - loss: 0.0051 - val_loss: 0.0046\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     validation_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(data_generator_val\u001b[38;5;241m.\u001b[39mgenerate_sample_pesq(batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m))\n\u001b[1;32m     15\u001b[0m     x_val, y_val \u001b[38;5;241m=\u001b[39m validation_batch\n\u001b[0;32m---> 17\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_generator_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_sample_pesq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m              \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m              \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m              \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;43;03m#               callbacks=[PlotLossesCallback()]\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = cnn()\n",
    "# model.summary()\n",
    "model.compile(optimizer='adam', loss='mse',)\n",
    "\n",
    "batch_size = 128\n",
    "steps_per_epoch = len(sound_base.train_X) // batch_size\n",
    "\n",
    "print('Starting training')\n",
    "\n",
    "for epoch in range(8):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    # Gera um novo lote de validação para cada época\n",
    "    validation_batch = next(data_generator_val.generate_sample_pesq(batch_size=1024))\n",
    "    x_val, y_val = validation_batch\n",
    "        \n",
    "    model.fit(data_generator_train.generate_sample_pesq(batch_size=batch_size),\n",
    "              steps_per_epoch=steps_per_epoch,\n",
    "              epochs=1,\n",
    "              validation_data=(x_val, y_val),\n",
    "#               callbacks=[PlotLossesCallback()]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24105a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('chech.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4c5d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
